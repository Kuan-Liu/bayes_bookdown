<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Session 5 Bayesian estimation with MCMC | HAD5314H - Applied Bayesian Methods in Clinical Epidemiology and Health Care Research</title>
  <meta name="description" content="Course notes for HAD5314H Winter 2022" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Session 5 Bayesian estimation with MCMC | HAD5314H - Applied Bayesian Methods in Clinical Epidemiology and Health Care Research" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://kuan-liu.github.io/bayes_bookdown/" />
  
  <meta property="og:description" content="Course notes for HAD5314H Winter 2022" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Session 5 Bayesian estimation with MCMC | HAD5314H - Applied Bayesian Methods in Clinical Epidemiology and Health Care Research" />
  
  <meta name="twitter:description" content="Course notes for HAD5314H Winter 2022" />
  

<meta name="author" content="Kuan Liu   Institute of Health Policy, Management and Evaluation   University of Toronto" />


<meta name="date" content="2022-02-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="Prior.html"/>
<link rel="next" href="BayesReg1.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">HAD5314H - Winter 2022 </a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>University of Toronto Statement of Acknowledgment of Traditional Land</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-info"><i class="fa fa-check"></i>Course Info</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-description"><i class="fa fa-check"></i>Course Description</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#course-textbook-and-structure"><i class="fa fa-check"></i>Course Textbook and Structure</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#calendar-and-outline"><i class="fa fa-check"></i>Calendar and Outline</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#accessibility-and-accommodations"><i class="fa fa-check"></i>Accessibility and Accommodations</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#academic-integrity"><i class="fa fa-check"></i>Academic Integrity</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#key-resources-and-supports-for-dslph-graduate-students"><i class="fa fa-check"></i>Key Resources and Supports for DSLPH Graduate Students</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="into.html"><a href="into.html"><i class="fa fa-check"></i><b>1</b> Introduction to the course</a>
<ul>
<li class="chapter" data-level="1.1" data-path="into.html"><a href="into.html#about-me"><i class="fa fa-check"></i><b>1.1</b> About me</a></li>
<li class="chapter" data-level="1.2" data-path="into.html"><a href="into.html#syllabus"><i class="fa fa-check"></i><b>1.2</b> Syllabus</a></li>
<li class="chapter" data-level="1.3" data-path="into.html"><a href="into.html#some-history"><i class="fa fa-check"></i><b>1.3</b> Some history</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="into.html"><a href="into.html#bayesian-history"><i class="fa fa-check"></i><b>1.3.1</b> Bayesian history</a></li>
<li class="chapter" data-level="1.3.2" data-path="into.html"><a href="into.html#history-of-this-course"><i class="fa fa-check"></i><b>1.3.2</b> History of this course</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="into.html"><a href="into.html#thinking-like-a-bayesian-using-the-concept-of-probability"><i class="fa fa-check"></i><b>1.4</b> Thinking like a Bayesian using the concept of probability</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="into.html"><a href="into.html#probability-is-not-unitary"><i class="fa fa-check"></i><b>1.4.1</b> Probability is not unitary</a></li>
<li class="chapter" data-level="1.4.2" data-path="into.html"><a href="into.html#bayes-rule"><i class="fa fa-check"></i><b>1.4.2</b> Bayes’ Rule</a></li>
<li class="chapter" data-level="1.4.3" data-path="into.html"><a href="into.html#the-scientific-method-in-steps"><i class="fa fa-check"></i><b>1.4.3</b> The Scientific Method in steps</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html"><i class="fa fa-check"></i>Lab1 Getting started with R &amp; RStudio</a>
<ul>
<li class="chapter" data-level="1.5" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#r-and-rstudio-installation"><i class="fa fa-check"></i><b>1.5</b> R and RStudio Installation</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#windows-operating-system"><i class="fa fa-check"></i><b>1.5.1</b> Windows operating system</a></li>
<li class="chapter" data-level="1.5.2" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#macos-operating-system"><i class="fa fa-check"></i><b>1.5.2</b> macOS operating system</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#r-packages"><i class="fa fa-check"></i><b>1.6</b> R Packages</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#bayesian-analysis-in-r-using-brms-package"><i class="fa fa-check"></i><b>1.6.1</b> Bayesian Analysis in R using brms package</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#working-in-rstudio"><i class="fa fa-check"></i><b>1.7</b> Working in RStudio</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#rstudio-layout"><i class="fa fa-check"></i><b>1.7.1</b> RStudio layout</a></li>
<li class="chapter" data-level="1.7.2" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#customization"><i class="fa fa-check"></i><b>1.7.2</b> Customization</a></li>
<li class="chapter" data-level="1.7.3" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#working-directory"><i class="fa fa-check"></i><b>1.7.3</b> Working directory</a></li>
<li class="chapter" data-level="1.7.4" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#getting-help-with-r"><i class="fa fa-check"></i><b>1.7.4</b> Getting help with R</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#basic-r-a-crash-introduction"><i class="fa fa-check"></i><b>1.8</b> Basic R (a crash introduction)</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#arithmetic"><i class="fa fa-check"></i><b>1.8.1</b> Arithmetic</a></li>
<li class="chapter" data-level="1.8.2" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#vectors"><i class="fa fa-check"></i><b>1.8.2</b> Vectors</a></li>
<li class="chapter" data-level="1.8.3" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#data-frame---the-titanic-dataset"><i class="fa fa-check"></i><b>1.8.3</b> Data frame - The Titanic dataset</a></li>
<li class="chapter" data-level="1.8.4" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#simple-plots"><i class="fa fa-check"></i><b>1.8.4</b> Simple plots</a></li>
<li class="chapter" data-level="" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#r-session-information"><i class="fa fa-check"></i>R Session information</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="prob.html"><a href="prob.html"><i class="fa fa-check"></i><b>2</b> Probability, random variables and distributions</a>
<ul>
<li class="chapter" data-level="2.1" data-path="prob.html"><a href="prob.html#probability"><i class="fa fa-check"></i><b>2.1</b> Probability</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="prob.html"><a href="prob.html#venn-diagrams"><i class="fa fa-check"></i><b>2.1.1</b> Venn Diagrams</a></li>
<li class="chapter" data-level="2.1.2" data-path="prob.html"><a href="prob.html#probability-rules"><i class="fa fa-check"></i><b>2.1.2</b> Probability Rules</a></li>
<li class="chapter" data-level="2.1.3" data-path="prob.html"><a href="prob.html#how-to-define-and-assign-probabilities-in-general"><i class="fa fa-check"></i><b>2.1.3</b> How to define and assign probabilities in general?</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="prob.html"><a href="prob.html#probability-distributions"><i class="fa fa-check"></i><b>2.2</b> Probability Distributions</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="prob.html"><a href="prob.html#probability-density-functions"><i class="fa fa-check"></i><b>2.2.1</b> Probability density functions</a></li>
<li class="chapter" data-level="2.2.2" data-path="prob.html"><a href="prob.html#discrete-distributions"><i class="fa fa-check"></i><b>2.2.2</b> Discrete Distributions</a></li>
<li class="chapter" data-level="2.2.3" data-path="prob.html"><a href="prob.html#continous-distributions"><i class="fa fa-check"></i><b>2.2.3</b> Continous Distributions</a></li>
<li class="chapter" data-level="" data-path="prob.html"><a href="prob.html#r-session-information-1"><i class="fa fa-check"></i>R Session information</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="bayes.html"><a href="bayes.html"><i class="fa fa-check"></i><b>3</b> Introduction to Bayesian inference</a>
<ul>
<li class="chapter" data-level="3.1" data-path="bayes.html"><a href="bayes.html#classical-frequentist-approach"><i class="fa fa-check"></i><b>3.1</b> Classical frequentist approach</a></li>
<li class="chapter" data-level="3.2" data-path="bayes.html"><a href="bayes.html#introduction-to-bayesian-approach"><i class="fa fa-check"></i><b>3.2</b> Introduction to Bayesian approach</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="bayes.html"><a href="bayes.html#review-from-session-1"><i class="fa fa-check"></i><b>3.2.1</b> Review from session 1</a></li>
<li class="chapter" data-level="3.2.2" data-path="bayes.html"><a href="bayes.html#the-beta-binomial-model"><i class="fa fa-check"></i><b>3.2.2</b> The Beta-binomial model</a></li>
<li class="chapter" data-level="3.2.3" data-path="bayes.html"><a href="bayes.html#the-normal-normal-model"><i class="fa fa-check"></i><b>3.2.3</b> The Normal-normal model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="bayes.html"><a href="bayes.html#summary-of-conjugate-priors-models"><i class="fa fa-check"></i><b>3.3</b> Summary of Conjugate priors &amp; models</a></li>
<li class="chapter" data-level="3.4" data-path="bayes.html"><a href="bayes.html#why-bayesian-statistical-estimation-revisit"><i class="fa fa-check"></i><b>3.4</b> Why Bayesian: Statistical Estimation Revisit</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="bayes.html"><a href="bayes.html#classic-frequentist-inference"><i class="fa fa-check"></i><b>3.4.1</b> Classic Frequentist Inference</a></li>
<li class="chapter" data-level="3.4.2" data-path="bayes.html"><a href="bayes.html#bayesian-inference"><i class="fa fa-check"></i><b>3.4.2</b> Bayesian Inference</a></li>
<li class="chapter" data-level="" data-path="bayes.html"><a href="bayes.html#r-session-information-2"><i class="fa fa-check"></i>R Session information</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Prior.html"><a href="Prior.html"><i class="fa fa-check"></i><b>4</b> Prior Distributions</a>
<ul>
<li class="chapter" data-level="4.1" data-path="Prior.html"><a href="Prior.html#choosing-priors"><i class="fa fa-check"></i><b>4.1</b> Choosing priors</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="Prior.html"><a href="Prior.html#eliciting-priors-from-experts"><i class="fa fa-check"></i><b>4.1.1</b> Eliciting priors from experts</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="Prior.html"><a href="Prior.html#default-clincial-priors"><i class="fa fa-check"></i><b>4.2</b> Default clincial priors</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="Prior.html"><a href="Prior.html#non-informative-or-reference-priors"><i class="fa fa-check"></i><b>4.2.1</b> “Non-informative” or “reference” priors</a></li>
<li class="chapter" data-level="4.2.2" data-path="Prior.html"><a href="Prior.html#minimally-informative-prior"><i class="fa fa-check"></i><b>4.2.2</b> Minimally informative prior</a></li>
<li class="chapter" data-level="4.2.3" data-path="Prior.html"><a href="Prior.html#skeptical-prior"><i class="fa fa-check"></i><b>4.2.3</b> Skeptical Prior</a></li>
<li class="chapter" data-level="4.2.4" data-path="Prior.html"><a href="Prior.html#optimisticenthusiastic-prior"><i class="fa fa-check"></i><b>4.2.4</b> Optimistic/enthusiastic Prior</a></li>
<li class="chapter" data-level="4.2.5" data-path="Prior.html"><a href="Prior.html#evaluating-priors"><i class="fa fa-check"></i><b>4.2.5</b> Evaluating Priors?</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="Prior.html"><a href="Prior.html#historical-data-meta-analysis"><i class="fa fa-check"></i><b>4.3</b> Historical data (meta-analysis)</a></li>
<li class="chapter" data-level="4.4" data-path="Prior.html"><a href="Prior.html#hierarchical-priors-and-shrinkage-priors"><i class="fa fa-check"></i><b>4.4</b> Hierarchical priors and shrinkage priors</a>
<ul>
<li class="chapter" data-level="" data-path="Prior.html"><a href="Prior.html#r-session-information-3"><i class="fa fa-check"></i>R Session information</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="BayesMCMC.html"><a href="BayesMCMC.html"><i class="fa fa-check"></i><b>5</b> Bayesian estimation with MCMC</a>
<ul>
<li class="chapter" data-level="5.1" data-path="BayesMCMC.html"><a href="BayesMCMC.html#introduction-to-markov-chain-monte-carlo-methods"><i class="fa fa-check"></i><b>5.1</b> Introduction to Markov Chain Monte Carlo Methods</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="BayesMCMC.html"><a href="BayesMCMC.html#gibbs-sampling"><i class="fa fa-check"></i><b>5.1.1</b> Gibbs sampling</a></li>
<li class="chapter" data-level="5.1.2" data-path="BayesMCMC.html"><a href="BayesMCMC.html#metropolis-algorithm"><i class="fa fa-check"></i><b>5.1.2</b> Metropolis algorithm</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="BayesMCMC.html"><a href="BayesMCMC.html#mcmc-diganostics---assess-convergence"><i class="fa fa-check"></i><b>5.2</b> MCMC diganostics - assess convergence</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="BayesMCMC.html"><a href="BayesMCMC.html#acceptance-rate"><i class="fa fa-check"></i><b>5.2.1</b> Acceptance Rate</a></li>
<li class="chapter" data-level="5.2.2" data-path="BayesMCMC.html"><a href="BayesMCMC.html#diagnostics-using-multiple-chains"><i class="fa fa-check"></i><b>5.2.2</b> Diagnostics Using Multiple Chains</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="BayesMCMC.html"><a href="BayesMCMC.html#example-bayesian-modelling-with-brms"><i class="fa fa-check"></i><b>5.3</b> Example Bayesian modelling with brms</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="BayesMCMC.html"><a href="BayesMCMC.html#bayesian-linear-regression"><i class="fa fa-check"></i><b>5.3.1</b> Bayesian linear regression</a></li>
<li class="chapter" data-level="5.3.2" data-path="BayesMCMC.html"><a href="BayesMCMC.html#bayesian-generalized-linear-regression"><i class="fa fa-check"></i><b>5.3.2</b> Bayesian generalized linear regression</a></li>
<li class="chapter" data-level="" data-path="BayesMCMC.html"><a href="BayesMCMC.html#r-session-information-4"><i class="fa fa-check"></i>R Session information</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="BayesReg1.html"><a href="BayesReg1.html"><i class="fa fa-check"></i><b>6</b> Bayesian Regression I</a>
<ul>
<li class="chapter" data-level="6.1" data-path="BayesReg1.html"><a href="BayesReg1.html#normal-models-and-linear-regression"><i class="fa fa-check"></i><b>6.1</b> Normal Models and Linear Regression</a></li>
<li class="chapter" data-level="6.2" data-path="BayesReg1.html"><a href="BayesReg1.html#hierarchical-models-and-convergence"><i class="fa fa-check"></i><b>6.2</b> Hierarchical models and convergence</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="BayesReg2.html"><a href="BayesReg2.html"><i class="fa fa-check"></i><b>7</b> Bayesian Regression II</a>
<ul>
<li class="chapter" data-level="7.1" data-path="BayesReg2.html"><a href="BayesReg2.html#models-for-binary-data"><i class="fa fa-check"></i><b>7.1</b> Models for Binary Data</a></li>
<li class="chapter" data-level="7.2" data-path="BayesReg2.html"><a href="BayesReg2.html#models-for-count-data"><i class="fa fa-check"></i><b>7.2</b> Models for Count Data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a> <a href="https://www.kuan-liu.com/" target="blank">Developed by Kuan Liu</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">HAD5314H - Applied Bayesian Methods in Clinical Epidemiology and Health Care Research</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="BayesMCMC" class="section level1" number="5">
<h1><span class="header-section-number">Session 5</span> Bayesian estimation with MCMC</h1>
<div class="chapterintro">
<ul>
<li>Introduction to MCMC and two common MCMC algorithm</li>
<li>MCMC in action with brms on Bayesian modelling</li>
<li>Learn about Markov chain diagnostics</li>
</ul>
</div>
<script src="hideOutput.js"></script>
<p></br></p>
<div id="introduction-to-markov-chain-monte-carlo-methods" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Introduction to Markov Chain Monte Carlo Methods</h2>
<ul>
<li><p>Oftentimes, the posterior distribution might not be easily determined (as in the case of conjugate models), especially when we are modelling multiple parameters</p></li>
<li><p>We need numerical ways to compute posterior distribution</p></li>
<li><p>Recall the posterior distribution takes form</p></li>
</ul>
<p><span class="math display">\[P(\theta \mid y) = \frac{P(y \mid \theta) \times P(\theta)}{ P(y)} = \frac{P(y \mid \theta) \ P(\theta)}{ \int P(y \mid \theta) \ P(\theta) \ d\theta}\]</span>
- The denominator <span class="math inline">\(\int P(y \mid \theta) \ P(\theta) \ d\theta\)</span> is the challenging part to be determined numerically.</p>
<ul>
<li><p>Markov chain simulation is used when it is not possible or not computationally efficient to sample <span class="math inline">\(\theta\)</span> directly from <span class="math inline">\(P(\theta \mid y)\)</span></p></li>
<li><p>instead we sample iteratively to draw from a distribution that becomes closer to <span class="math inline">\(P(\theta \mid y)\)</span></p></li>
<li><p>Markov Chain simulation methods comprise a class of algorithms for sampling from a (complex) probability distribution and have application outside Bayesian statistics as well, especially in statistical optimization</p>
<ul>
<li>Markov chain is named after Russian mathematician <a href="https://en.wikipedia.org/wiki/Andrey_Markov">Andrey Markov (1856-1922)</a>.</li>
<li>A Markov chain or Markov process is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event.</li>
</ul></li>
</ul>
<p><strong>Monte Carlo sampling</strong></p>
<ul>
<li>Notation:
<ul>
<li>Let <span class="math inline">\(\theta = (\theta_1, \ldots, \theta_p)\)</span> be the collection of <span class="math inline">\(p\)</span> number of parameters in a Bayesian model</li>
<li>Let <span class="math inline">\(Y = (Y_1, \ldots, Y_n)\)</span> be the observed data of <span class="math inline">\(n\)</span> subjects</li>
<li>The posterior <span class="math inline">\(P(\theta \mid Y)\)</span> is a probability distribution</li>
<li>If <span class="math inline">\(\theta^{(1)}, \ldots, \theta^{(s)}\)</span> are <span class="math inline">\(s\)</span> samples from <span class="math inline">\(P(\theta \mid Y)\)</span>, then the mean of the <span class="math inline">\(s\)</span> samples approximate the posterior mean!</li>
<li>This posterior draws provides approximations of the posterior summaries of interest (e.g., posterior mean, posterior medium, P(theta &lt; 0.9), etc)</li>
</ul></li>
<li>How to draw samples from some arbitrary distribution <span class="math inline">\(P(\theta \mid Y)\)</span>?
<ul>
<li>There are many algorithms and software options for performing MC sampling</li>
<li>Software:
<ul>
<li>OpenBUGS, WinBUGS, JAGS;</li>
<li>STAN;</li>
<li>INLA (Iteratively Nested Laplace Approximation, this is not MC)</li>
</ul></li>
</ul></li>
<li>In this session, we will introduce two MCMC algorithms: Metropolis algorithm and Gibbs sampler.
<ul>
<li>brms package uses stan which samples following Hamiltonian Monte Carlo (HMC) algorithm and No-U-Turn Sampler (NUTS)</li>
<li>HMC is a bit more complex, we will not cover the algorithm in this session, for those who are interested see <a href="http://www.mcmchandbook.net/HandbookChapter5.pdf" class="uri">http://www.mcmchandbook.net/HandbookChapter5.pdf</a> and <span class="citation">(<a href="#ref-hoffman2014no" role="doc-biblioref">Hoffman, Gelman, et al. 2014</a>)</span></li>
<li>HMC is documented to be more efficient then Gibbs and Metropolis algorithm (less iterations are needed).</li>
</ul></li>
<li>Online interactive MCMC demonstration app, <a href="https://chi-feng.github.io/mcmc-demo/" class="uri">https://chi-feng.github.io/mcmc-demo/</a></li>
</ul>
<div id="gibbs-sampling" class="section level3" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Gibbs sampling</h3>
<p>As a simple example, suppose we want to estimate mean <span class="math inline">\(\mu\)</span> and precision <span class="math inline">\(\tau = 1/\sigma^2\)</span> of a normal distribution. We place the priors <span class="math inline">\(\mu \sim N(0,1)\)</span> and <span class="math inline">\(\tau \sim Gamma(1,1)\)</span>.</p>
<p><span class="math display">\[ Y \mid \mu, \tau \sim N(\mu, \frac{1}{\tau})\]</span>
<span class="math display">\[\mu \sim N(0,1)\]</span>
<span class="math display">\[\tau \sim Gamma(1,1)\]</span></p>
<p>Then the conditional posterior distributions for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span> are</p>
<p><span class="math display">\[ P( \mu \mid \tau, Y) \propto N(\frac{\tau \sum_{i=1}^n y_i}{1 + n \tau},\frac{1}{1+n\tau})\]</span></p>
<p><span class="math display">\[ P( \tau \mid \mu, Y) \propto Gamma(1 + \frac{n}{2}, 1+\frac{\sum_{i=1}^n (y_i-\mu)^2}{2})\]</span></p>
<p>We want to alternate between sampling from these two conditional posteriors.</p>
<ul>
<li><p>Let’s simulate <span class="math inline">\(n=100\)</span> data, <span class="math inline">\(Y\)</span>, from N(10,1). The true data mean <span class="math inline">\(\mu = 10\)</span> and <span class="math inline">\(\tau = 1\)</span>, our posterior distribution of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\tau\)</span> should approximate the true value</p></li>
<li><p>First, let’s complete Gibbs sampling with 10 draws</p>
<ol style="list-style-type: decimal">
<li>we specify an initial value of <span class="math inline">\((\mu^{(1)}, \tau^{(1)}) = (1,1)\)</span> to start our chain</li>
<li>Given <span class="math inline">\(\tau^{(1)} = 1\)</span>, plug in this value to <span class="math inline">\(P( \mu \mid \tau, Y) \propto N(\frac{ \sum_{i=1}^{100} y_i}{1 + 100 },\frac{1}{1+100})\)</span>, now <strong>we draw 1 sample of <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\mu^{(2)}\)</span> from P( , Y)</strong></li>
<li>Given <span class="math inline">\(\mu^{(1)} = 1\)</span> plug in this value to <span class="math inline">\(P( \tau \mid \mu, Y) \propto Gamma(1 + \frac{100}{2}, 1+\frac{\sum_{i=1}^{100} (y_i-1)^2}{2})\)</span>, now <strong>we draw 1 sample of <span class="math inline">\(\tau\)</span>, $ from <span class="math inline">\(P( \tau \mid \mu, Y)\)</span></strong></li>
<li>we repeat sample 2 and 3 and construct a posterior set of <span class="math inline">\((\mu^{(1)}, \tau^{(1)}, \ldots, (\mu^{(10)}, \tau^{(10)}))\)</span></li>
</ol></li>
</ul>
<div class="fold s">

<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="BayesMCMC.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1-2"><a href="BayesMCMC.html#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="BayesMCMC.html#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Prior distribution for mu and tau;</span></span>
<span id="cb1-4"><a href="BayesMCMC.html#cb1-4" aria-hidden="true" tabindex="-1"></a>prior_mean <span class="ot">&lt;-</span> <span class="dv">0</span>       <span class="co"># the prior on mu;</span></span>
<span id="cb1-5"><a href="BayesMCMC.html#cb1-5" aria-hidden="true" tabindex="-1"></a>prior_precision <span class="ot">&lt;-</span> <span class="dv">1</span>  <span class="co"># the prior on mu;</span></span>
<span id="cb1-6"><a href="BayesMCMC.html#cb1-6" aria-hidden="true" tabindex="-1"></a>prior_shape <span class="ot">&lt;-</span> <span class="dv">1</span>      <span class="co"># alpha in prior for precision;</span></span>
<span id="cb1-7"><a href="BayesMCMC.html#cb1-7" aria-hidden="true" tabindex="-1"></a>prior_rate <span class="ot">&lt;-</span> <span class="dv">1</span>       <span class="co"># beta in prior for precision;</span></span>
<span id="cb1-8"><a href="BayesMCMC.html#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="BayesMCMC.html#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># data likelihood - simulated from N(10,1)</span></span>
<span id="cb1-10"><a href="BayesMCMC.html#cb1-10" aria-hidden="true" tabindex="-1"></a>num_obs <span class="ot">&lt;-</span> <span class="dv">100</span>         <span class="co"># size of our data</span></span>
<span id="cb1-11"><a href="BayesMCMC.html#cb1-11" aria-hidden="true" tabindex="-1"></a>true_mean <span class="ot">&lt;-</span> <span class="dv">10</span>        </span>
<span id="cb1-12"><a href="BayesMCMC.html#cb1-12" aria-hidden="true" tabindex="-1"></a>true_precision <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb1-13"><a href="BayesMCMC.html#cb1-13" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(num_obs, true_mean, <span class="dv">1</span><span class="sc">/</span><span class="fu">sqrt</span>(true_precision))</span>
<span id="cb1-14"><a href="BayesMCMC.html#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="BayesMCMC.html#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># number of Gibbs samples of posterior draws;</span></span>
<span id="cb1-16"><a href="BayesMCMC.html#cb1-16" aria-hidden="true" tabindex="-1"></a>num_sample <span class="ot">&lt;-</span> <span class="dv">10</span>    </span>
<span id="cb1-17"><a href="BayesMCMC.html#cb1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-18"><a href="BayesMCMC.html#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># posterior sample vector initiated with NULL value;</span></span>
<span id="cb1-19"><a href="BayesMCMC.html#cb1-19" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, num_sample)</span>
<span id="cb1-20"><a href="BayesMCMC.html#cb1-20" aria-hidden="true" tabindex="-1"></a>tau <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, num_sample)</span>
<span id="cb1-21"><a href="BayesMCMC.html#cb1-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-22"><a href="BayesMCMC.html#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co">#initialize values on mu and tau</span></span>
<span id="cb1-23"><a href="BayesMCMC.html#cb1-23" aria-hidden="true" tabindex="-1"></a>mu[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">1</span> </span>
<span id="cb1-24"><a href="BayesMCMC.html#cb1-24" aria-hidden="true" tabindex="-1"></a>tau[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb1-25"><a href="BayesMCMC.html#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="BayesMCMC.html#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">2</span><span class="sc">:</span>num_sample){</span>
<span id="cb1-27"><a href="BayesMCMC.html#cb1-27" aria-hidden="true" tabindex="-1"></a>  <span class="co"># i %% 2 means for i mod 2 == 0, that is for i with even value;</span></span>
<span id="cb1-28"><a href="BayesMCMC.html#cb1-28" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(i <span class="sc">%%</span> <span class="dv">2</span>){</span>
<span id="cb1-29"><a href="BayesMCMC.html#cb1-29" aria-hidden="true" tabindex="-1"></a>    mu[i] <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(</span>
<span id="cb1-30"><a href="BayesMCMC.html#cb1-30" aria-hidden="true" tabindex="-1"></a>      <span class="dv">1</span>, </span>
<span id="cb1-31"><a href="BayesMCMC.html#cb1-31" aria-hidden="true" tabindex="-1"></a>      <span class="at">mean =</span> (prior_precision <span class="sc">*</span> prior_mean <span class="sc">+</span> tau[i<span class="dv">-1</span>] <span class="sc">*</span> <span class="fu">sum</span>(Y)) <span class="sc">/</span> </span>
<span id="cb1-32"><a href="BayesMCMC.html#cb1-32" aria-hidden="true" tabindex="-1"></a>        (prior_precision <span class="sc">+</span> num_obs <span class="sc">*</span> tau[i<span class="dv">-1</span>]),</span>
<span id="cb1-33"><a href="BayesMCMC.html#cb1-33" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd =</span> <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">/</span> (prior_precision <span class="sc">+</span> num_obs <span class="sc">*</span> tau[i<span class="dv">-1</span>]))</span>
<span id="cb1-34"><a href="BayesMCMC.html#cb1-34" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-35"><a href="BayesMCMC.html#cb1-35" aria-hidden="true" tabindex="-1"></a>    tau[i] <span class="ot">&lt;-</span> tau[i<span class="dv">-1</span>]</span>
<span id="cb1-36"><a href="BayesMCMC.html#cb1-36" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span>{</span>
<span id="cb1-37"><a href="BayesMCMC.html#cb1-37" aria-hidden="true" tabindex="-1"></a>    mu[i] <span class="ot">&lt;-</span> mu[i<span class="dv">-1</span>]</span>
<span id="cb1-38"><a href="BayesMCMC.html#cb1-38" aria-hidden="true" tabindex="-1"></a>    tau[i] <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(</span>
<span id="cb1-39"><a href="BayesMCMC.html#cb1-39" aria-hidden="true" tabindex="-1"></a>      <span class="dv">1</span>,</span>
<span id="cb1-40"><a href="BayesMCMC.html#cb1-40" aria-hidden="true" tabindex="-1"></a>      <span class="at">shape =</span> prior_shape <span class="sc">+</span> num_obs <span class="sc">/</span> <span class="dv">2</span>,</span>
<span id="cb1-41"><a href="BayesMCMC.html#cb1-41" aria-hidden="true" tabindex="-1"></a>      <span class="at">rate =</span> prior_rate <span class="sc">+</span> <span class="fu">sum</span>((Y <span class="sc">-</span> mu[i])<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb1-42"><a href="BayesMCMC.html#cb1-42" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb1-43"><a href="BayesMCMC.html#cb1-43" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-44"><a href="BayesMCMC.html#cb1-44" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-45"><a href="BayesMCMC.html#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="BayesMCMC.html#cb1-46" aria-hidden="true" tabindex="-1"></a>posterior <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">order =</span> <span class="dv">1</span><span class="sc">:</span>num_sample, mu, tau)</span>
<span id="cb1-47"><a href="BayesMCMC.html#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="BayesMCMC.html#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(posterior, <span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> tau, <span class="at">label =</span> order)) <span class="sc">+</span></span>
<span id="cb1-49"><a href="BayesMCMC.html#cb1-49" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb1-50"><a href="BayesMCMC.html#cb1-50" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="at">hjust=</span><span class="dv">0</span>, <span class="at">vjust=</span><span class="dv">0</span>) <span class="sc">+</span> </span>
<span id="cb1-51"><a href="BayesMCMC.html#cb1-51" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_path</span>(<span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> tau), <span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span></span>
<span id="cb1-52"><a href="BayesMCMC.html#cb1-52" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="fu">paste0</span>(<span class="st">&#39;Path plot of Gibbs sampling with &#39;</span>, num_sample, <span class="st">&#39; draws&#39;</span>) )<span class="sc">+</span></span>
<span id="cb1-53"><a href="BayesMCMC.html#cb1-53" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="fu">expression</span>(mu)) <span class="sc">+</span></span>
<span id="cb1-54"><a href="BayesMCMC.html#cb1-54" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="fu">expression</span>(tau)) <span class="sc">+</span></span>
<span id="cb1-55"><a href="BayesMCMC.html#cb1-55" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<img src="bayes_bookdown_files/figure-html/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" />
<div>

<ul>
<li>Now, let’s complete Gibbs sampling with 2000 draws
<ul>
<li>we also consider discarding the first 1000 draws (burn-in) and making posterior inference using only the last 900 draws!</li>
</ul></li>
</ul>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;" /><img src="bayes_bookdown_files/figure-html/unnamed-chunk-3-2.png" width="768" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="BayesMCMC.html#cb2-1" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(posterior[(burnin<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>num_sample,]) <span class="sc">+</span></span>
<span id="cb2-2"><a href="BayesMCMC.html#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(</span>
<span id="cb2-3"><a href="BayesMCMC.html#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x =</span> mu, <span class="at">y =</span> <span class="fu">stat</span>(count) <span class="sc">/</span> <span class="fu">sum</span>(count)),</span>
<span id="cb2-4"><a href="BayesMCMC.html#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb2-5"><a href="BayesMCMC.html#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(</span>
<span id="cb2-6"><a href="BayesMCMC.html#cb2-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fu">quantile</span>(posterior[(burnin<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>num_sample,<span class="dv">2</span>], <span class="fl">0.025</span>)), </span>
<span id="cb2-7"><a href="BayesMCMC.html#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">&#39;red&#39;</span>) <span class="sc">+</span></span>
<span id="cb2-8"><a href="BayesMCMC.html#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(</span>
<span id="cb2-9"><a href="BayesMCMC.html#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="dv">10</span>), </span>
<span id="cb2-10"><a href="BayesMCMC.html#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">&#39;red&#39;</span>) <span class="sc">+</span></span>
<span id="cb2-11"><a href="BayesMCMC.html#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(</span>
<span id="cb2-12"><a href="BayesMCMC.html#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fu">quantile</span>(posterior[(burnin<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>num_sample,<span class="dv">2</span>], <span class="fl">0.975</span>)), </span>
<span id="cb2-13"><a href="BayesMCMC.html#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">&#39;red&#39;</span>) <span class="sc">+</span></span>
<span id="cb2-14"><a href="BayesMCMC.html#cb2-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&#39;Posterior distribution - Relative frequency&#39;</span>) <span class="sc">+</span></span>
<span id="cb2-15"><a href="BayesMCMC.html#cb2-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="fu">expression</span>(mu)) <span class="sc">+</span></span>
<span id="cb2-16"><a href="BayesMCMC.html#cb2-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="fu">bquote</span>(<span class="st">&#39;With burn-in, 95% credible interval of &#39;</span> <span class="sc">~</span> mu))</span>
<span id="cb2-17"><a href="BayesMCMC.html#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="BayesMCMC.html#cb2-18" aria-hidden="true" tabindex="-1"></a>p4 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(posterior[(burnin<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>num_sample,]) <span class="sc">+</span></span>
<span id="cb2-19"><a href="BayesMCMC.html#cb2-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(</span>
<span id="cb2-20"><a href="BayesMCMC.html#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x =</span> tau, <span class="at">y =</span> <span class="fu">stat</span>(count) <span class="sc">/</span> <span class="fu">sum</span>(count)), </span>
<span id="cb2-21"><a href="BayesMCMC.html#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb2-22"><a href="BayesMCMC.html#cb2-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(</span>
<span id="cb2-23"><a href="BayesMCMC.html#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fu">quantile</span>(posterior[(burnin<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>num_sample,<span class="dv">3</span>], <span class="fl">0.025</span>)), </span>
<span id="cb2-24"><a href="BayesMCMC.html#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">&#39;red&#39;</span>) <span class="sc">+</span></span>
<span id="cb2-25"><a href="BayesMCMC.html#cb2-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(</span>
<span id="cb2-26"><a href="BayesMCMC.html#cb2-26" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="dv">1</span>), </span>
<span id="cb2-27"><a href="BayesMCMC.html#cb2-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">&#39;red&#39;</span>) <span class="sc">+</span></span>
<span id="cb2-28"><a href="BayesMCMC.html#cb2-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(</span>
<span id="cb2-29"><a href="BayesMCMC.html#cb2-29" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fu">quantile</span>(posterior[(burnin<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>num_sample,<span class="dv">3</span>], <span class="fl">0.975</span>)), </span>
<span id="cb2-30"><a href="BayesMCMC.html#cb2-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">&#39;red&#39;</span>) <span class="sc">+</span></span>
<span id="cb2-31"><a href="BayesMCMC.html#cb2-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">&#39;Posterior distribution - Relative frequency&#39;</span>) <span class="sc">+</span></span>
<span id="cb2-32"><a href="BayesMCMC.html#cb2-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="fu">expression</span>(tau)) <span class="sc">+</span></span>
<span id="cb2-33"><a href="BayesMCMC.html#cb2-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="fu">bquote</span>(<span class="st">&#39;With burn-in, 95% credible interval of &#39;</span> <span class="sc">~</span> tau))</span>
<span id="cb2-34"><a href="BayesMCMC.html#cb2-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-35"><a href="BayesMCMC.html#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="fu">ggarrange</span>(p3, p4, <span class="at">nrow =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="BayesMCMC.html#cb3-1" aria-hidden="true" tabindex="-1"></a>p5 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(posterior[(burnin<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>num_sample,]) <span class="sc">+</span></span>
<span id="cb3-2"><a href="BayesMCMC.html#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(</span>
<span id="cb3-3"><a href="BayesMCMC.html#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x =</span> order, <span class="at">y =</span> mu)) <span class="sc">+</span></span>
<span id="cb3-4"><a href="BayesMCMC.html#cb3-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(</span>
<span id="cb3-5"><a href="BayesMCMC.html#cb3-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">yintercept =</span> <span class="dv">10</span>), </span>
<span id="cb3-6"><a href="BayesMCMC.html#cb3-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">&#39;red&#39;</span>) <span class="sc">+</span></span>
<span id="cb3-7"><a href="BayesMCMC.html#cb3-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="fu">expression</span>(mu)) <span class="sc">+</span></span>
<span id="cb3-8"><a href="BayesMCMC.html#cb3-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&#39;posterior draws&#39;</span>) <span class="sc">+</span></span>
<span id="cb3-9"><a href="BayesMCMC.html#cb3-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="fu">bquote</span>(<span class="st">&#39;Trace plot with burn-in of&#39;</span> <span class="sc">~</span> mu))</span>
<span id="cb3-10"><a href="BayesMCMC.html#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="BayesMCMC.html#cb3-11" aria-hidden="true" tabindex="-1"></a>p6 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(posterior[(burnin<span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span>num_sample,]) <span class="sc">+</span></span>
<span id="cb3-12"><a href="BayesMCMC.html#cb3-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(</span>
<span id="cb3-13"><a href="BayesMCMC.html#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x =</span> order, <span class="at">y =</span> tau)) <span class="sc">+</span></span>
<span id="cb3-14"><a href="BayesMCMC.html#cb3-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(</span>
<span id="cb3-15"><a href="BayesMCMC.html#cb3-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">yintercept =</span> <span class="dv">1</span>), </span>
<span id="cb3-16"><a href="BayesMCMC.html#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">&#39;red&#39;</span>) <span class="sc">+</span></span>
<span id="cb3-17"><a href="BayesMCMC.html#cb3-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="fu">expression</span>(tau)) <span class="sc">+</span></span>
<span id="cb3-18"><a href="BayesMCMC.html#cb3-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&#39;posterior draws&#39;</span>) <span class="sc">+</span></span>
<span id="cb3-19"><a href="BayesMCMC.html#cb3-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="fu">bquote</span>(<span class="st">&#39;Trace plot with burn-in of&#39;</span> <span class="sc">~</span> tau))</span>
<span id="cb3-20"><a href="BayesMCMC.html#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="BayesMCMC.html#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="fu">ggarrange</span>(p5, p6, <span class="at">nrow =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-5-1.png" width="768" style="display: block; margin: auto;" /></p>
<p><strong>Summary</strong></p>
<ul>
<li>OpenBUGS, WinBUGS, and JAGS use Gibbs sampling</li>
<li>Gibbs sampling relies on <strong>conditional distributions</strong> as proposal distributions to sample each dimension the posterior distributions.</li>
<li>Gibbs sampling generates a <strong>Markov chain</strong> of samples, each of which is correlated with nearby samples.
<ul>
<li>in the example here, the next draw is sampled from posterior calculated using the previous draw!</li>
</ul></li>
<li>Generally, samples from the beginning of the chain (the burn-in period) may not accurately represent the desired distribution and are usually discarded</li>
</ul>
</div>
<div id="metropolis-algorithm" class="section level3" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Metropolis algorithm</h3>
<ul>
<li><p>Metropolis algorithm is an adaptation of a random walk with an acceptance/rejection rule to converge to a specified distribution</p></li>
<li><p>The algorithm generally follows the following steps (following the Gibbs’ example):</p></li>
</ul>
<ol style="list-style-type: decimal">
<li><p>We specify an initial value of <span class="math inline">\((\mu^{(1)}, \tau^{(1)}) = (1,1)\)</span> to start our chain</p></li>
<li><p>Sample from a proposal joint distribution values for <span class="math inline">\((\mu^{(propose)}, \tau^{(propose)})\)</span></p></li>
<li><p>Calculate the ratio (r) of the densities</p></li>
</ol>
<p><span class="math display">\[r = \frac{P(\mu^{(propose)}, \tau^{(propose)} \mid y)}{P((\mu^{(1)}, \tau^{(1)} \mid y)} = \frac{P(y \mid \mu^{(propose)}, \tau^{(propose)}) P(\mu^{(propose)}) P(\tau^{(propose)})}{P(y \mid \mu^{(1)}, \tau^{(1)}) P(\mu^{(1)}) P(\tau^{(1)})}\]</span>
- for this step, we can format the ratio in its log scale for easy calculation, log(r)!</p>
<ol start="4" style="list-style-type: decimal">
<li><p>Sample “u” from an uniform distribution, <span class="math inline">\(u \sim Unif(0,1)\)</span></p></li>
<li><p>accept the proposed values, <span class="math inline">\((\mu^{(2)}, \tau^{(2)}) = (\mu^{(propose)}, \tau^{(propose)})\)</span> if <span class="math inline">\(u &lt; \min(1,r)\)</span>, otherwise reject the proposed values, keep <span class="math inline">\((\mu^{(2)}, \tau^{(2)}) = (\mu^{(1)}, \tau^{(1)})\)</span></p></li>
<li><p>repeat step 2 to 5 for multiple iterations, forming our posterior draws!</p></li>
</ol>
<ul>
<li>For this demonstration, we complete 10,000 iterations with first 5000 draws as burn-in</li>
</ul>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="BayesMCMC.html#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="do">############################</span></span>
<span id="cb4-2"><a href="BayesMCMC.html#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="do">##Joint distribution of mu and tau</span></span>
<span id="cb4-3"><a href="BayesMCMC.html#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="do">###########################</span></span>
<span id="cb4-4"><a href="BayesMCMC.html#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="BayesMCMC.html#cb4-5" aria-hidden="true" tabindex="-1"></a>loglikelihood<span class="ot">&lt;-</span><span class="cf">function</span>(data,mu,sigma){</span>
<span id="cb4-6"><a href="BayesMCMC.html#cb4-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-7"><a href="BayesMCMC.html#cb4-7" aria-hidden="true" tabindex="-1"></a>  loglikelihoodValue<span class="ot">=</span><span class="dv">0</span></span>
<span id="cb4-8"><a href="BayesMCMC.html#cb4-8" aria-hidden="true" tabindex="-1"></a>  loglikelihoodValue<span class="ot">=</span><span class="fu">sum</span>(<span class="fu">dnorm</span>(data,<span class="at">mean=</span>mu,<span class="at">sd=</span>sigma,<span class="at">log=</span><span class="cn">TRUE</span>))</span>
<span id="cb4-9"><a href="BayesMCMC.html#cb4-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-10"><a href="BayesMCMC.html#cb4-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(loglikelihoodValue)</span>
<span id="cb4-11"><a href="BayesMCMC.html#cb4-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-12"><a href="BayesMCMC.html#cb4-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-13"><a href="BayesMCMC.html#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="BayesMCMC.html#cb4-14" aria-hidden="true" tabindex="-1"></a>priormu <span class="ot">&lt;-</span> <span class="cf">function</span>(mu){</span>
<span id="cb4-15"><a href="BayesMCMC.html#cb4-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">dnorm</span>(mu,<span class="dv">0</span>,<span class="dv">1</span>,<span class="at">log=</span><span class="cn">TRUE</span>))</span>
<span id="cb4-16"><a href="BayesMCMC.html#cb4-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-17"><a href="BayesMCMC.html#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="BayesMCMC.html#cb4-18" aria-hidden="true" tabindex="-1"></a>priorsigma2 <span class="ot">&lt;-</span> <span class="cf">function</span>(sigma2){</span>
<span id="cb4-19"><a href="BayesMCMC.html#cb4-19" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-20"><a href="BayesMCMC.html#cb4-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">dunif</span>(sigma2,<span class="at">min=</span><span class="dv">0</span>,<span class="at">max=</span><span class="dv">100</span>,<span class="at">log=</span><span class="cn">TRUE</span>))</span>
<span id="cb4-21"><a href="BayesMCMC.html#cb4-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-22"><a href="BayesMCMC.html#cb4-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-23"><a href="BayesMCMC.html#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="BayesMCMC.html#cb4-24" aria-hidden="true" tabindex="-1"></a>joint <span class="ot">&lt;-</span> <span class="cf">function</span>(mu,sigma){</span>
<span id="cb4-25"><a href="BayesMCMC.html#cb4-25" aria-hidden="true" tabindex="-1"></a>  data<span class="ot">=</span>Y</span>
<span id="cb4-26"><a href="BayesMCMC.html#cb4-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span> (<span class="fu">loglikelihood</span>(data,mu,sigma) <span class="sc">+</span> <span class="fu">priormu</span>(mu)<span class="sc">+</span><span class="fu">priorsigma2</span>(sigma<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb4-27"><a href="BayesMCMC.html#cb4-27" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-28"><a href="BayesMCMC.html#cb4-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-29"><a href="BayesMCMC.html#cb4-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-30"><a href="BayesMCMC.html#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="co">#Defining the Metropolis Algorithm as a function</span></span>
<span id="cb4-31"><a href="BayesMCMC.html#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="co">#the arguments of the functions are the initial values for mu and sigma passed as a vector (startvalue) and the total number of iterations.</span></span>
<span id="cb4-32"><a href="BayesMCMC.html#cb4-32" aria-hidden="true" tabindex="-1"></a>run_Metropolis <span class="ot">&lt;-</span> <span class="cf">function</span>(startvalue, iterations){</span>
<span id="cb4-33"><a href="BayesMCMC.html#cb4-33" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-34"><a href="BayesMCMC.html#cb4-34" aria-hidden="true" tabindex="-1"></a><span class="co">#Matrix to save the 2 parameters of the chain </span></span>
<span id="cb4-35"><a href="BayesMCMC.html#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="co">#Number of rows= number of iterations +1 and number of columns equals to the number of parameters.(2)</span></span>
<span id="cb4-36"><a href="BayesMCMC.html#cb4-36" aria-hidden="true" tabindex="-1"></a>chain <span class="ot">=</span> <span class="fu">array</span>(<span class="at">dim =</span> <span class="fu">c</span>(iterations<span class="sc">+</span><span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb4-37"><a href="BayesMCMC.html#cb4-37" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-38"><a href="BayesMCMC.html#cb4-38" aria-hidden="true" tabindex="-1"></a><span class="co">#Initialize the first row of the chain matrix with the initial values for the parameters.</span></span>
<span id="cb4-39"><a href="BayesMCMC.html#cb4-39" aria-hidden="true" tabindex="-1"></a>chain[<span class="dv">1</span>,] <span class="ot">=</span> startvalue</span>
<span id="cb4-40"><a href="BayesMCMC.html#cb4-40" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-41"><a href="BayesMCMC.html#cb4-41" aria-hidden="true" tabindex="-1"></a><span class="co">#variables that save the number of accepted and rejected values</span></span>
<span id="cb4-42"><a href="BayesMCMC.html#cb4-42" aria-hidden="true" tabindex="-1"></a>naceito<span class="ot">=</span><span class="dv">0</span></span>
<span id="cb4-43"><a href="BayesMCMC.html#cb4-43" aria-hidden="true" tabindex="-1"></a>nrejeitado<span class="ot">=</span><span class="dv">0</span></span>
<span id="cb4-44"><a href="BayesMCMC.html#cb4-44" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-45"><a href="BayesMCMC.html#cb4-45" aria-hidden="true" tabindex="-1"></a><span class="co">#Loop with Metropolis Algorithm</span></span>
<span id="cb4-46"><a href="BayesMCMC.html#cb4-46" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>iterations){</span>
<span id="cb4-47"><a href="BayesMCMC.html#cb4-47" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-48"><a href="BayesMCMC.html#cb4-48" aria-hidden="true" tabindex="-1"></a><span class="co">#Proposal value for mu. This is a sample from a normal distribution with mean equals to the mu value of the previous step of the chain and standard deviation equals to 1.</span></span>
<span id="cb4-49"><a href="BayesMCMC.html#cb4-49" aria-hidden="true" tabindex="-1"></a>proposalmu<span class="ot">=</span><span class="fu">rnorm</span>(<span class="dv">1</span>,<span class="at">mean=</span> chain[i,<span class="dv">1</span>],<span class="at">sd=</span><span class="fl">0.1</span>)</span>
<span id="cb4-50"><a href="BayesMCMC.html#cb4-50" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-51"><a href="BayesMCMC.html#cb4-51" aria-hidden="true" tabindex="-1"></a><span class="co">#Proposal value for sigma. This is a sample from an uniform distribution with tuning adjustment;</span></span>
<span id="cb4-52"><a href="BayesMCMC.html#cb4-52" aria-hidden="true" tabindex="-1"></a>proposalsigma<span class="ot">=</span>chain[i,<span class="dv">2</span>]<span class="sc">+</span><span class="fu">runif</span>(<span class="dv">1</span>,<span class="at">min=</span><span class="sc">-</span><span class="fl">0.5</span>,<span class="at">max=</span><span class="fl">0.5</span>)</span>
<span id="cb4-53"><a href="BayesMCMC.html#cb4-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-54"><a href="BayesMCMC.html#cb4-54" aria-hidden="true" tabindex="-1"></a><span class="co">#Log of the Acceptance ratio for Metropolis Algorithm</span></span>
<span id="cb4-55"><a href="BayesMCMC.html#cb4-55" aria-hidden="true" tabindex="-1"></a>razao<span class="ot">=</span><span class="fu">joint</span>(proposalmu,proposalsigma)<span class="sc">-</span><span class="fu">joint</span>(chain[i,<span class="dv">1</span>],chain[i,<span class="dv">2</span>])</span>
<span id="cb4-56"><a href="BayesMCMC.html#cb4-56" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-57"><a href="BayesMCMC.html#cb4-57" aria-hidden="true" tabindex="-1"></a><span class="co">#Error treatment. If for some reason the ratio results in a not a number value then we keep the same value of the current step for the next step of the chain.</span></span>
<span id="cb4-58"><a href="BayesMCMC.html#cb4-58" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (<span class="fu">exp</span>(razao) <span class="sc">==</span> <span class="st">&quot;NaN&quot;</span>){</span>
<span id="cb4-59"><a href="BayesMCMC.html#cb4-59" aria-hidden="true" tabindex="-1"></a>      chain[i<span class="sc">+</span><span class="dv">1</span>,]<span class="ot">=</span>chain[i,]</span>
<span id="cb4-60"><a href="BayesMCMC.html#cb4-60" aria-hidden="true" tabindex="-1"></a>      nrejeitado<span class="ot">=</span>nrejeitado<span class="sc">+</span><span class="dv">1</span></span>
<span id="cb4-61"><a href="BayesMCMC.html#cb4-61" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb4-62"><a href="BayesMCMC.html#cb4-62" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-63"><a href="BayesMCMC.html#cb4-63" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span></span>
<span id="cb4-64"><a href="BayesMCMC.html#cb4-64" aria-hidden="true" tabindex="-1"></a><span class="co"># Draw a number between 0 and 1 and compare it with the calculated ratio of acceptance. Once we used the log of the ratio, we need to power it to &quot;e&quot; exponent to recover the correct scale of the real ratio.      </span></span>
<span id="cb4-65"><a href="BayesMCMC.html#cb4-65" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb4-66"><a href="BayesMCMC.html#cb4-66" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span>(<span class="fu">runif</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">1</span>)<span class="sc">&lt;</span><span class="fu">min</span>(<span class="dv">1</span>,<span class="fu">exp</span>(razao))){</span>
<span id="cb4-67"><a href="BayesMCMC.html#cb4-67" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-68"><a href="BayesMCMC.html#cb4-68" aria-hidden="true" tabindex="-1"></a>        chain[i<span class="sc">+</span><span class="dv">1</span>,]<span class="ot">=</span><span class="fu">c</span>(proposalmu,proposalsigma)</span>
<span id="cb4-69"><a href="BayesMCMC.html#cb4-69" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb4-70"><a href="BayesMCMC.html#cb4-70" aria-hidden="true" tabindex="-1"></a>        <span class="co">#counting acceptance</span></span>
<span id="cb4-71"><a href="BayesMCMC.html#cb4-71" aria-hidden="true" tabindex="-1"></a>        naceito<span class="ot">=</span>naceito<span class="sc">+</span><span class="dv">1</span></span>
<span id="cb4-72"><a href="BayesMCMC.html#cb4-72" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb4-73"><a href="BayesMCMC.html#cb4-73" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-74"><a href="BayesMCMC.html#cb4-74" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>{</span>
<span id="cb4-75"><a href="BayesMCMC.html#cb4-75" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb4-76"><a href="BayesMCMC.html#cb4-76" aria-hidden="true" tabindex="-1"></a><span class="co">#Rejecting the proposal value and keeping the current parameters value to the next step of the chain.</span></span>
<span id="cb4-77"><a href="BayesMCMC.html#cb4-77" aria-hidden="true" tabindex="-1"></a>      chain[i<span class="sc">+</span><span class="dv">1</span>,] <span class="ot">=</span> chain[i,]</span>
<span id="cb4-78"><a href="BayesMCMC.html#cb4-78" aria-hidden="true" tabindex="-1"></a>      nrejeitado<span class="ot">=</span>nrejeitado<span class="sc">+</span><span class="dv">1</span></span>
<span id="cb4-79"><a href="BayesMCMC.html#cb4-79" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb4-80"><a href="BayesMCMC.html#cb4-80" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb4-81"><a href="BayesMCMC.html#cb4-81" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb4-82"><a href="BayesMCMC.html#cb4-82" aria-hidden="true" tabindex="-1"></a> <span class="co">#Creates and returns a list with the chain with all parameters values, the number of accepted and rejected values</span></span>
<span id="cb4-83"><a href="BayesMCMC.html#cb4-83" aria-hidden="true" tabindex="-1"></a>  lista<span class="ot">=</span><span class="fu">list</span>(chain,naceito,nrejeitado)</span>
<span id="cb4-84"><a href="BayesMCMC.html#cb4-84" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-85"><a href="BayesMCMC.html#cb4-85" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(lista)</span>
<span id="cb4-86"><a href="BayesMCMC.html#cb4-86" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-87"><a href="BayesMCMC.html#cb4-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-88"><a href="BayesMCMC.html#cb4-88" aria-hidden="true" tabindex="-1"></a><span class="co">#Running the model</span></span>
<span id="cb4-89"><a href="BayesMCMC.html#cb4-89" aria-hidden="true" tabindex="-1"></a><span class="co">#Setting the number of iterations</span></span>
<span id="cb4-90"><a href="BayesMCMC.html#cb4-90" aria-hidden="true" tabindex="-1"></a>iterations<span class="ot">=</span><span class="dv">10000</span></span>
<span id="cb4-91"><a href="BayesMCMC.html#cb4-91" aria-hidden="true" tabindex="-1"></a><span class="co">#Setting the initial values for mu and sigma</span></span>
<span id="cb4-92"><a href="BayesMCMC.html#cb4-92" aria-hidden="true" tabindex="-1"></a>startvalue<span class="ot">=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb4-93"><a href="BayesMCMC.html#cb4-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-94"><a href="BayesMCMC.html#cb4-94" aria-hidden="true" tabindex="-1"></a><span class="co">#Calling Metropolis function and saving the output in resultsM variable</span></span>
<span id="cb4-95"><a href="BayesMCMC.html#cb4-95" aria-hidden="true" tabindex="-1"></a>resultsM<span class="ot">=</span><span class="fu">run_Metropolis</span>(startvalue,iterations)</span>
<span id="cb4-96"><a href="BayesMCMC.html#cb4-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-97"><a href="BayesMCMC.html#cb4-97" aria-hidden="true" tabindex="-1"></a><span class="co">#Computing the acceptance rate</span></span>
<span id="cb4-98"><a href="BayesMCMC.html#cb4-98" aria-hidden="true" tabindex="-1"></a>acptRate<span class="ot">=</span>resultsM[[<span class="dv">2</span>]]<span class="sc">/</span>(resultsM[[<span class="dv">3</span>]])</span>
<span id="cb4-99"><a href="BayesMCMC.html#cb4-99" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;acceptance rate:&quot;</span>, <span class="fu">round</span>(acptRate,<span class="dv">2</span>))) </span></code></pre></div>
<pre><code>## [1] &quot;acceptance rate: 0.22&quot;</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="BayesMCMC.html#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Recording the chain for mu and sigma</span></span>
<span id="cb6-2"><a href="BayesMCMC.html#cb6-2" aria-hidden="true" tabindex="-1"></a>chainM<span class="ot">=</span><span class="fu">data.frame</span>(<span class="at">order =</span> <span class="dv">1</span><span class="sc">:</span>(iterations<span class="sc">+</span><span class="dv">1</span>),</span>
<span id="cb6-3"><a href="BayesMCMC.html#cb6-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">mu =</span> resultsM[[<span class="dv">1</span>]][,<span class="dv">1</span>],</span>
<span id="cb6-4"><a href="BayesMCMC.html#cb6-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">sigma =</span> resultsM[[<span class="dv">1</span>]][,<span class="dv">2</span>])</span></code></pre></div>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-7-1.png" width="768" style="display: block; margin: auto;" /><img src="bayes_bookdown_files/figure-html/unnamed-chunk-7-2.png" width="768" style="display: block; margin: auto;" />
<strong>Summary</strong></p>
<ul>
<li><p>Metropolis-Hastings (MH) generalizes Metropolis algorithm to non-symmetric proposal distributions while maintaining detailed balance.</p></li>
<li><p>Metropolis algorithm requires us to specify a proposal distribution involving some tuning, this can be tricky to set-up. A “bad” tuning parameter can result in lower acceptance rate (i.e., proposed value keeps getting rejected).</p></li>
<li><p>Metropolis algorithm generates a Markov chain of samples, each of which is correlated with nearby samples.</p>
<ul>
<li>in the example here, the next proposed value for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> is sampled from the proposal distribution using the previous draw!</li>
</ul></li>
<li><p>Again, it’s a good practice to disgard begining of the chain!</p></li>
</ul>
</div>
</div>
<div id="mcmc-diganostics---assess-convergence" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> MCMC diganostics - assess convergence</h2>
<ul>
<li><p>What does a good Markov chain look like?</p></li>
<li><p>How can we tell if our Markov chain sample produces a reasonable approximation of the posterior?</p></li>
<li><p>How big should our Markov chain sample size be? How many iterations to run?</p></li>
<li><p>In this section, we provide a few diagnostic rules and principles</p></li>
<li><p>A good reference paper on Bayesian workflow: <a href="https://arxiv.org/pdf/2011.01808.pdf" class="uri">https://arxiv.org/pdf/2011.01808.pdf</a>, <span class="citation">(<a href="#ref-gelman2020bayesian" role="doc-biblioref">Gelman et al. 2020</a>)</span></p></li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-8"></span>
<img src="images/bayes_workflow.JPG" alt="Bayesian workflow - Figure 1 from Gelman at al 2020" width="410" />
<p class="caption">
Figure 5.1: Bayesian workflow - Figure 1 from Gelman at al 2020
</p>
</div>
<p><strong>1. Choose good initial values and discard early iterations</strong></p>
<p><strong>2. Assessing convergence in long-run</strong></p>
<ul>
<li><p>A commonly used numerical index in diagnosing convergence is <span class="math inline">\(\hat{R}\)</span>, also
called the potential scale reduction factor, proposed by Gelman and Rubin (1992)
and later an extension for multivariate distributions by Brooks and Gelman
(1997).</p></li>
<li><p><span class="math inline">\(\hat{R}\)</span> measures the ratio of the total variability combining multiple
chains to the within-chain variability.</p>
<ul>
<li>recall in ANOVA, the <span class="math inline">\(F\)</span>-ratio is a measure of</li>
</ul></li>
</ul>
<p><span class="math display">\[F = \frac{\text{Between-group difference} + \text{error}}{\text{error}}\]</span></p>
<ul>
<li><span class="math inline">\(\hat{R}\)</span> has a very similar meaning conceptually, with <code>error</code> meaning the
within-chain variance.
<ul>
<li>after the chains converge, there should be no differences between the chains, and so<span class="math inline">\(\hat{R}\)</span> should be very close to 1.0.</li>
</ul></li>
<li>It’s recommended an <span class="math inline">\(\hat{R}\)</span> less than 1.1 for acceptable convergence of the Markov chains, but more recently a more stringent cutoff of 1.01 is proposed.</li>
</ul>
<p><strong>Good Mixing - trace plot and auto-correlation plot</strong></p>
<ul>
<li><p>One thing you should look at to diagnose the convergence of a Markov chain is the trace plot.</p></li>
<li><p>Good mixing behaviour as it explores the region with most of the density smoothly and bounces from one point to another quickly.</p></li>
<li><p>Bad mixing:</p>
<ul>
<li>although in every iteration a jump is made to a new value, the jump to the new value is relatively small, so it gonna takes a long time to get from one end of the distribution to another end,</li>
<li>and it rarely explores all regions, therefore, if you stop the chain “early,” you can get a biased representation of the posterior distribution.</li>
</ul></li>
</ul>
<p><strong>Dependence of the iterations</strong></p>
<ul>
<li><p>Autocorrelation provides another metric by which to evaluate whether our Markov chain sufficiently mimics the behaviour of an independent sample.</p></li>
<li><p><strong>Strong autocorrelation</strong> or dependence is a bad thing – it goes hand in hand with small effective sample size ratios, and thus provides a warning sign that our resulting posterior approximations might be unreliable.</p></li>
<li><p>Autocorrelation</p>
<ul>
<li>Lag 1 autocorrelation measures the correlation between pairs of Markov chain values that are one “step” apart</li>
<li>Lag k autocorrelation measures the correlation between pairs of Markov chain values that are k “steps” apart</li>
<li>we can look at ACF plot for diagnostics, in R this can be examined using acf() function!</li>
</ul></li>
</ul>
<div class="fold s">

<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="BayesMCMC.html#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Gibbs example;</span></span>
<span id="cb7-2"><a href="BayesMCMC.html#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(posterior[(<span class="dv">1000</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span><span class="fu">length</span>(posterior<span class="sc">$</span>mu),<span class="dv">2</span>], <span class="at">main=</span><span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&quot;Gibbs example &quot;</span>,mu)))</span></code></pre></div>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="BayesMCMC.html#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">acf</span>(posterior[(<span class="dv">1000</span><span class="sc">+</span><span class="dv">1</span>)<span class="sc">:</span><span class="fu">length</span>(posterior<span class="sc">$</span>tau),<span class="dv">3</span>], <span class="at">main=</span><span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&quot;Gibbs example &quot;</span>,tau)))</span></code></pre></div>
<img src="bayes_bookdown_files/figure-html/unnamed-chunk-9-2.png" width="672" />
<div>

<p><strong>Thinning</strong></p>
<ul>
<li>we can perform thinning to achieve faster convergence!
<ul>
<li>thinning the MCMC by keeping every kth simulation draw and discarding the rest</li>
<li>for example, thin = 5, referring to keeping the 5th, 10th, …, draws only! If the total MCMC iteration is 2000, for thin = 5, we will end-up with a posterior sample distribution of size = 2000/5 = 400.</li>
</ul></li>
</ul>
<div id="acceptance-rate" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Acceptance Rate</h3>
<ul>
<li><p>If you’re using the Metropolis/MH algorithm, you want to monitor the acceptance
rate and make sure it is within optimal range.</p></li>
<li><p>If you accept almost every time, that tells you that each time the chain only jumps a very small step (so that the acceptance ratio is close to 1 every time), which will make the algorithm slow in converging to the stationary distribution.</p></li>
<li><p>If the acceptance rate is very low, then that says that the chain got stuck to just a few locations and it takes hundreds of iterations for it to make one jump.</p></li>
<li><p>For the Metropolis/MH algorithm, an optimal acceptance rate would be something between 10% to 60%.</p></li>
</ul>
</div>
<div id="diagnostics-using-multiple-chains" class="section level3" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Diagnostics Using Multiple Chains</h3>
<ul>
<li><p>Another important thing to check is to see the convergence with multiple chains.</p></li>
<li><p>So far we’ve been just talking about one chain, but it is common practice to use
two or more chains (and 4 chains are generally recommended nowadays),</p>
<ul>
<li>each starting at a different, preferably more extreme, place, and see whether they explore a similar region.</li>
</ul></li>
</ul>
</div>
</div>
<div id="example-bayesian-modelling-with-brms" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Example Bayesian modelling with brms</h2>
<div id="bayesian-linear-regression" class="section level3" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Bayesian linear regression</h3>
</div>
<div id="bayesian-generalized-linear-regression" class="section level3" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> Bayesian generalized linear regression</h3>
</div>
<div id="r-session-information-4" class="section level3 unnumbered">
<h3>R Session information</h3>
<pre><code>## R version 4.0.5 (2021-03-31)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 19042)
## 
## Matrix products: 
## 
## locale:
## [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252   
## [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C                   
## [5] LC_TIME=English_Canada.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] invgamma_1.1    bayesplot_1.8.1 MCMCpack_1.6-0  MASS_7.3-53.1  
##  [5] coda_0.19-4     ggmcmc_1.5.1.1  brms_2.16.3     Rcpp_1.0.7     
##  [9] ggpubr_0.4.0    forcats_0.5.1   stringr_1.4.0   dplyr_1.0.7    
## [13] purrr_0.3.4     readr_2.1.1     tidyr_1.1.4     tibble_3.1.6   
## [17] ggplot2_3.3.5   tidyverse_1.3.1</code></pre>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-gelman2020bayesian" class="csl-entry">
Gelman, Andrew, Aki Vehtari, Daniel Simpson, Charles C Margossian, Bob Carpenter, Yuling Yao, Lauren Kennedy, Jonah Gabry, Paul-Christian Bürkner, and Martin Modrák. 2020. <span>“Bayesian Workflow.”</span> <em>arXiv Preprint arXiv:2011.01808</em>.
</div>
<div id="ref-hoffman2014no" class="csl-entry">
Hoffman, Matthew D, Andrew Gelman, et al. 2014. <span>“The No-u-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian Monte Carlo.”</span> <em>J. Mach. Learn. Res.</em> 15 (1): 1593–623.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="Prior.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="BayesReg1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": "twitter"
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Session 3 Introduction to Bayesian inference | HAD5314H - Applied Bayesian Methods in Clinical Epidemiology and Health Care Research</title>
  <meta name="description" content="Course notes for HAD5314H Winter 2022" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Session 3 Introduction to Bayesian inference | HAD5314H - Applied Bayesian Methods in Clinical Epidemiology and Health Care Research" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://kuan-liu.github.io/bayes_bookdown/" />
  
  <meta property="og:description" content="Course notes for HAD5314H Winter 2022" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Session 3 Introduction to Bayesian inference | HAD5314H - Applied Bayesian Methods in Clinical Epidemiology and Health Care Research" />
  
  <meta name="twitter:description" content="Course notes for HAD5314H Winter 2022" />
  

<meta name="author" content="Kuan Liu   Institute of Health Policy, Management and Evaluation   University of Toronto" />


<meta name="date" content="2022-01-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="prob.html"/>
<link rel="next" href="Prior.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">HAD5314H - Winter 2022 </a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>University of Toronto Statement of Acknowledgment of Traditional Land</a></li>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html"><i class="fa fa-check"></i>Course Syllabus</a>
<ul>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html#course-info"><i class="fa fa-check"></i>Course Info</a></li>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html#course-description"><i class="fa fa-check"></i>Course Description</a></li>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html#course-textbook-and-structure"><i class="fa fa-check"></i>Course Textbook and Structure</a></li>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html#calendar-and-outline"><i class="fa fa-check"></i>Calendar and Outline</a></li>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html#accessibility-and-accommodations"><i class="fa fa-check"></i>Accessibility and Accommodations</a></li>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html#academic-integrity"><i class="fa fa-check"></i>Academic Integrity</a></li>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html#key-resources-and-supports-for-dslph-graduate-students"><i class="fa fa-check"></i>Key Resources and Supports for DSLPH Graduate Students</a></li>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="into.html"><a href="into.html"><i class="fa fa-check"></i><b>1</b> Introduction to the course</a>
<ul>
<li class="chapter" data-level="1.1" data-path="into.html"><a href="into.html#about-me"><i class="fa fa-check"></i><b>1.1</b> About me</a></li>
<li class="chapter" data-level="1.2" data-path="into.html"><a href="into.html#syllabus"><i class="fa fa-check"></i><b>1.2</b> Syllabus</a></li>
<li class="chapter" data-level="1.3" data-path="into.html"><a href="into.html#some-history"><i class="fa fa-check"></i><b>1.3</b> Some history</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="into.html"><a href="into.html#bayesian-history"><i class="fa fa-check"></i><b>1.3.1</b> Bayesian history</a></li>
<li class="chapter" data-level="1.3.2" data-path="into.html"><a href="into.html#history-of-this-course"><i class="fa fa-check"></i><b>1.3.2</b> History of this course</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="into.html"><a href="into.html#thinking-like-a-bayesian-using-the-concept-of-probability"><i class="fa fa-check"></i><b>1.4</b> Thinking like a Bayesian using the concept of probability</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="into.html"><a href="into.html#probability-is-not-unitary"><i class="fa fa-check"></i><b>1.4.1</b> Probability is not unitary</a></li>
<li class="chapter" data-level="1.4.2" data-path="into.html"><a href="into.html#bayes-rule"><i class="fa fa-check"></i><b>1.4.2</b> Bayes’ Rule</a></li>
<li class="chapter" data-level="1.4.3" data-path="into.html"><a href="into.html#the-scientific-method-in-steps"><i class="fa fa-check"></i><b>1.4.3</b> The Scientific Method in steps</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html"><i class="fa fa-check"></i>Lab1 Getting started with R &amp; RStudio</a>
<ul>
<li class="chapter" data-level="1.5" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#r-and-rstudio-installation"><i class="fa fa-check"></i><b>1.5</b> R and RStudio Installation</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#windows-operating-system"><i class="fa fa-check"></i><b>1.5.1</b> Windows operating system</a></li>
<li class="chapter" data-level="1.5.2" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#macos-operating-system"><i class="fa fa-check"></i><b>1.5.2</b> macOS operating system</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#r-packages"><i class="fa fa-check"></i><b>1.6</b> R Packages</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#bayesian-analysis-in-r-using-brms-package"><i class="fa fa-check"></i><b>1.6.1</b> Bayesian Analysis in R using brms package</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#working-in-rstudio"><i class="fa fa-check"></i><b>1.7</b> Working in RStudio</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#rstudio-layout"><i class="fa fa-check"></i><b>1.7.1</b> RStudio layout</a></li>
<li class="chapter" data-level="1.7.2" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#customization"><i class="fa fa-check"></i><b>1.7.2</b> Customization</a></li>
<li class="chapter" data-level="1.7.3" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#working-directory"><i class="fa fa-check"></i><b>1.7.3</b> Working directory</a></li>
<li class="chapter" data-level="1.7.4" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#getting-help-with-r"><i class="fa fa-check"></i><b>1.7.4</b> Getting help with R</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#basic-r-a-crash-introduction"><i class="fa fa-check"></i><b>1.8</b> Basic R (a crash introduction)</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#arithmetic"><i class="fa fa-check"></i><b>1.8.1</b> Arithmetic</a></li>
<li class="chapter" data-level="1.8.2" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#vectors"><i class="fa fa-check"></i><b>1.8.2</b> Vectors</a></li>
<li class="chapter" data-level="1.8.3" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#data-frame---the-titanic-dataset"><i class="fa fa-check"></i><b>1.8.3</b> Data frame - The Titanic dataset</a></li>
<li class="chapter" data-level="1.8.4" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#simple-plots"><i class="fa fa-check"></i><b>1.8.4</b> Simple plots</a></li>
<li class="chapter" data-level="" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#r-session-information"><i class="fa fa-check"></i>R Session information</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="prob.html"><a href="prob.html"><i class="fa fa-check"></i><b>2</b> Probability, random variables and distributions</a>
<ul>
<li class="chapter" data-level="2.1" data-path="prob.html"><a href="prob.html#probability"><i class="fa fa-check"></i><b>2.1</b> Probability</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="prob.html"><a href="prob.html#venn-diagrams"><i class="fa fa-check"></i><b>2.1.1</b> Venn Diagrams</a></li>
<li class="chapter" data-level="2.1.2" data-path="prob.html"><a href="prob.html#probability-rules"><i class="fa fa-check"></i><b>2.1.2</b> Probability Rules</a></li>
<li class="chapter" data-level="2.1.3" data-path="prob.html"><a href="prob.html#how-to-define-and-assign-probabilities-in-general"><i class="fa fa-check"></i><b>2.1.3</b> How to define and assign probabilities in general?</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="prob.html"><a href="prob.html#probability-distributions"><i class="fa fa-check"></i><b>2.2</b> Probability Distributions</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="prob.html"><a href="prob.html#probability-density-functions"><i class="fa fa-check"></i><b>2.2.1</b> Probability density functions</a></li>
<li class="chapter" data-level="2.2.2" data-path="prob.html"><a href="prob.html#discrete-distributions"><i class="fa fa-check"></i><b>2.2.2</b> Discrete Distributions</a></li>
<li class="chapter" data-level="2.2.3" data-path="prob.html"><a href="prob.html#continous-distributions"><i class="fa fa-check"></i><b>2.2.3</b> Continous Distributions</a></li>
<li class="chapter" data-level="" data-path="prob.html"><a href="prob.html#r-session-information-1"><i class="fa fa-check"></i>R Session information</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="bayes.html"><a href="bayes.html"><i class="fa fa-check"></i><b>3</b> Introduction to Bayesian inference</a>
<ul>
<li class="chapter" data-level="3.1" data-path="bayes.html"><a href="bayes.html#classical-frequentist-approach"><i class="fa fa-check"></i><b>3.1</b> Classical frequentist approach</a></li>
<li class="chapter" data-level="3.2" data-path="bayes.html"><a href="bayes.html#introduction-to-bayesian-approach"><i class="fa fa-check"></i><b>3.2</b> Introduction to Bayesian approach</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="bayes.html"><a href="bayes.html#review-from-session-1"><i class="fa fa-check"></i><b>3.2.1</b> Review from session 1</a></li>
<li class="chapter" data-level="3.2.2" data-path="bayes.html"><a href="bayes.html#the-beta-binomial-model"><i class="fa fa-check"></i><b>3.2.2</b> The Beta-binomial model</a></li>
<li class="chapter" data-level="3.2.3" data-path="bayes.html"><a href="bayes.html#the-normal-normal-model"><i class="fa fa-check"></i><b>3.2.3</b> The Normal-normal model</a></li>
<li class="chapter" data-level="" data-path="bayes.html"><a href="bayes.html#r-session-information-2"><i class="fa fa-check"></i>R Session information</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Prior.html"><a href="Prior.html"><i class="fa fa-check"></i><b>4</b> Considering Prior Distributions</a></li>
<li class="chapter" data-level="5" data-path="BayesReg.html"><a href="BayesReg.html"><i class="fa fa-check"></i><b>5</b> Bayesian Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="BayesReg.html"><a href="BayesReg.html#normal-models-and-linear-regression"><i class="fa fa-check"></i><b>5.1</b> Normal Models and Linear Regression</a></li>
<li class="chapter" data-level="5.2" data-path="BayesReg.html"><a href="BayesReg.html#hierarchical-models-and-convergence"><i class="fa fa-check"></i><b>5.2</b> Hierarchical models and convergence</a></li>
<li class="chapter" data-level="5.3" data-path="BayesReg.html"><a href="BayesReg.html#models-for-binary-data"><i class="fa fa-check"></i><b>5.3</b> Models for Binary Data</a></li>
<li class="chapter" data-level="5.4" data-path="BayesReg.html"><a href="BayesReg.html#models-for-count-data"><i class="fa fa-check"></i><b>5.4</b> Models for Count Data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a> <a href="https://www.kuan-liu.com/" target="blank">Developed by Kuan Liu</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">HAD5314H - Applied Bayesian Methods in Clinical Epidemiology and Health Care Research</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bayes" class="section level1" number="3">
<h1><span class="header-section-number">Session 3</span> Introduction to Bayesian inference</h1>
<div class="chapterintro">
<ul>
<li>Review of frequentist inferential approaches</li>
<li>Introduce Bayesian inference</li>
<li>Learn two simple Bayesian models (Beta-binomial &amp; normal-normal)</li>
<li>Discuss practical advantages and disadvantages of Bayesian approach</li>
</ul>
</div>
<script src="hideOutput.js"></script>
<p></br></p>
<div id="classical-frequentist-approach" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Classical frequentist approach</h2>
<ul>
<li><p>The classical (frequentist) statistical approach takes many forms, but the most wide-ranging is the likelihood-based approach</p></li>
<li><p>This approach specifies a distributional form for data and considers the
parameters of the distributions to be fixed constants to be estimated.</p></li>
<li><p>The parameters are estimated by finding the values that maximize the
likelihood (hence the name)</p></li>
</ul>
<blockquote>
<p>i.e. given the observed data, and assuming they come from specific distributions, what are the parameter values for these distributions that maximize the likelihood of these data?</p>
</blockquote>
<div class="important">
<p><strong>Review of likelihood function</strong></p>
<ul>
<li>Given a statistical model with some parameters (let’s call them <span class="math inline">\(\theta\)</span>), and given a set of observed data of size <span class="math inline">\(n\)</span>, <span class="math inline">\(D = \{x_1, x_2, \ldots, x_n \}\)</span>, the likelihood function, <span class="math inline">\(L(\theta, D)\)</span> is a  function that for every value of <span class="math inline">\(\theta\)</span> is equal to the probability (mass or density) of observing <span class="math inline">\(D\)</span> given <span class="math inline">\(\theta\)</span></li>
<li>i.e. <span class="math inline">\(L(\theta, D) = L_D(\theta) = P(Data | \theta)\)</span></li>
<li>if we assume <span class="math inline">\(x_1, x_2, \ldots, x_n\)</span> are independent and identically distributed, we can express the likelihood function as</li>
</ul>
<p><span class="math display">\[ L(\theta, D) = P(x_1 \mid \theta)\times P(x_2 \mid \theta) \ldots \times P(x_n \mid \theta) = \prod_{i=1}^n P(x_i\mid \theta).\]</span></p>
<p><strong>Example - Bernoulli trials</strong> Suppose we want to estimate the risk of death <span class="math inline">\(\theta\)</span> after a surgery</p>
<ul>
<li>We assume that every patient has the same risk <span class="math inline">\(\theta\)</span></li>
<li>We collect data from 10 surgeries and we find that 3 patients died and 7 survived,</li>
<li>What is the likelihood function for <span class="math inline">\(\theta\)</span> in this example?</li>
</ul>
<p>The distribution for each patient is <span class="math inline">\(Bernoulli(\theta)\)</span>  the probability of the number of those who died out of <span class="math inline">\(n\)</span> (here <span class="math inline">\(n\)</span>=10) is <span class="math inline">\(Binomial(\theta, 10)\)</span></p>
<p>The probability mass function of the binomial is <span class="math display">\[p(x|\theta, n) = {n \choose x} \theta^x (1-\theta)^{n-x}\]</span></p>
<p>The likelihood function of the observed data (3 deaths out of 10) given <span class="math inline">\(\theta\)</span> is <span class="math display">\[ L_D(\theta) = p(x=3| \theta) = {10 \choose 3} \theta^3 (1-\theta)^{10-3} \propto \theta^3 (1-\theta)^{10-3}\]</span></p>
<p><strong>Maximum Likelihood Estimator</strong></p>
<ul>
<li>The value that maximizes the likelihood function is called the maximum likelihood estimator or MLE</li>
<li>It is the “most likely” value for <span class="math inline">\(\theta\)</span> given the observed data</li>
<li>In this example it is equal to <span class="math inline">\(\hat{\theta}_{mle} = \frac{x}{n} = \frac{3}{10}=0.3\)</span> (the observed proportion of event), which can be obtained by taking the first derivative of the loglikelihood and calculate the value of <span class="math inline">\(\theta\)</span> that yields</li>
</ul>
<p><span class="math display">\[\begin{aligned}
LogL(\theta, D) &amp;= log({10 \choose 3}) + 3\ log(\theta) + (10-3)\ log(1- \theta) \\
\frac{\partial}{\partial \theta}LogL(\theta, D) &amp; = \frac{3}{\theta} - \frac{10-3}{1-p} = 0 \\
\hat{\theta}_{mle} &amp; = \frac{3}{10}=0.3
\end{aligned}\]</span></p>
<ul>
<li>It is the most commonly method to estimate a parameter in frequentist statistics</li>
</ul>
</div>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="bayes.html#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co">#simulating a sequence of probability representing parameter \theta;</span></span>
<span id="cb29-2"><a href="bayes.html#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="co">#\theta, probability of success, value between 0 and 1;</span></span>
<span id="cb29-3"><a href="bayes.html#cb29-3" aria-hidden="true" tabindex="-1"></a>theta <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">length=</span><span class="dv">1000</span>) </span>
<span id="cb29-4"><a href="bayes.html#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co">#coding Binomial likelihood given x = 3 and n = 10;</span></span>
<span id="cb29-5"><a href="bayes.html#cb29-5" aria-hidden="true" tabindex="-1"></a>L <span class="ot">&lt;-</span> <span class="fu">choose</span>(<span class="dv">10</span>,<span class="dv">3</span>)<span class="sc">*</span>theta<span class="sc">^</span><span class="dv">3</span><span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>theta)<span class="sc">^</span>(<span class="dv">10-3</span>)</span>
<span id="cb29-6"><a href="bayes.html#cb29-6" aria-hidden="true" tabindex="-1"></a><span class="co">#coding log Binomial likelihood given x = 3 and n = 10;</span></span>
<span id="cb29-7"><a href="bayes.html#cb29-7" aria-hidden="true" tabindex="-1"></a>logL <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="fu">choose</span>(<span class="dv">10</span>,<span class="dv">3</span>)) <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span><span class="fu">log</span>(theta)<span class="sc">+</span> (<span class="dv">10-3</span>)<span class="sc">*</span><span class="fu">log</span>((<span class="dv">1</span><span class="sc">-</span>theta))</span>
<span id="cb29-8"><a href="bayes.html#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Ploting likelihood function</span></span>
<span id="cb29-9"><a href="bayes.html#cb29-9" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">theta=</span>theta, <span class="at">L=</span>L)</span>
<span id="cb29-10"><a href="bayes.html#cb29-10" aria-hidden="true" tabindex="-1"></a>p1<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>d, <span class="fu">aes</span>(theta,L)) <span class="sc">+</span></span>
<span id="cb29-11"><a href="bayes.html#cb29-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>()<span class="sc">+</span></span>
<span id="cb29-12"><a href="bayes.html#cb29-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(<span class="st">&quot;Binomial likelihood x = 3 and n=10&quot;</span>) <span class="sc">+</span> </span>
<span id="cb29-13"><a href="bayes.html#cb29-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>()</span>
<span id="cb29-14"><a href="bayes.html#cb29-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Ploting likelihood function</span></span>
<span id="cb29-15"><a href="bayes.html#cb29-15" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">theta=</span>theta, <span class="at">logL=</span>logL)</span>
<span id="cb29-16"><a href="bayes.html#cb29-16" aria-hidden="true" tabindex="-1"></a>p2<span class="ot">&lt;-</span><span class="fu">ggplot</span>(<span class="at">data=</span>d, <span class="fu">aes</span>(theta,logL)) <span class="sc">+</span></span>
<span id="cb29-17"><a href="bayes.html#cb29-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>()<span class="sc">+</span></span>
<span id="cb29-18"><a href="bayes.html#cb29-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(<span class="st">&quot;Log Binomial likelihood x = 3 and n=10&quot;</span>) <span class="sc">+</span> </span>
<span id="cb29-19"><a href="bayes.html#cb29-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>()</span>
<span id="cb29-20"><a href="bayes.html#cb29-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-21"><a href="bayes.html#cb29-21" aria-hidden="true" tabindex="-1"></a><span class="fu">ggarrange</span>(p1, p2,  <span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">nrow =</span> <span class="dv">1</span>)</span></code></pre></div>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-39-1.png" width="768" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="bayes.html#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co">#negative loglikelihood function of binomial;</span></span>
<span id="cb30-2"><a href="bayes.html#cb30-2" aria-hidden="true" tabindex="-1"></a>neglogL <span class="ot">&lt;-</span> <span class="cf">function</span>(theta){<span class="sc">-</span><span class="fu">sum</span>(<span class="fu">dbinom</span>(<span class="at">x=</span><span class="dv">3</span>, <span class="at">size =</span> <span class="dv">10</span>, theta, <span class="at">log =</span> <span class="cn">TRUE</span>))}</span>
<span id="cb30-3"><a href="bayes.html#cb30-3" aria-hidden="true" tabindex="-1"></a><span class="co">#optimize:</span></span>
<span id="cb30-4"><a href="bayes.html#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="fu">optim</span>(<span class="at">par =</span> <span class="fl">0.5</span>, <span class="at">fn=</span>neglogL, <span class="at">method =</span> <span class="st">&quot;Brent&quot;</span>, <span class="at">lower =</span> <span class="dv">0</span>, <span class="at">upper =</span> <span class="dv">1</span>, <span class="at">hessian =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## $par
## [1] 0.3
## 
## $value
## [1] 1.321151
## 
## $counts
## function gradient 
##       NA       NA 
## 
## $convergence
## [1] 0
## 
## $message
## NULL
## 
## $hessian
##          [,1]
## [1,] 47.61985</code></pre>
<div class="important">
<p><strong>Maximum Likelihood confidence interval</strong></p>
<p>MLE satisfies the following two properties called <strong>consistency</strong> and <strong>asymptotic normality</strong>.</p>
<ol style="list-style-type: decimal">
<li><p><strong>Consistency.</strong> We say that an estimate <span class="math inline">\(\hat{\theta}\)</span> is consistent if <span class="math inline">\(\hat{\theta} \rightarrow \theta_0\)</span> as <span class="math inline">\(n \rightarrow \infty\)</span>, where <span class="math inline">\(\theta_0\)</span> is the true unknown parameter and <span class="math inline">\(n\)</span> is sample size.</p></li>
<li><p><strong>Asymptotic normality</strong> <span class="math inline">\(\hat{\theta}\)</span> is asymptotic normality if</p></li>
</ol>
<p><span class="math display">\[ \sqrt{n} (\hat{\theta} - \theta_0) \rightarrow^d N(0, \sigma_{\theta_0}^2) \]</span>
where <span class="math inline">\(\sigma_{\theta_0}^2)\)</span> is the asymptotic variance of the estimate <span class="math inline">\(\hat{\theta}\)</span>. Asymptotic normality says that the estimator not only converges to the unknown parameter, but it converges fast enough, at a rate <span class="math inline">\(1/\sqrt{n}\)</span>.</p>
<p>Given this properties, we can use <strong>Fisher information</strong> to estimate the variance of MLE and subsequently obtaining confidence intervals.
- MLE Asymptotic normality with Fisher information, <span class="math inline">\(I(\theta_0)\)</span></p>
<p><span class="math display">\[ \sqrt{n} (\hat{\theta}_{mle} - \theta_0) \rightarrow^d N(0, \frac{1}{I(\theta_0)}) \]</span></p>
<ul>
<li><p>Fisher information is defined using the second derivative of the loglikelihood.
<span class="math display">\[ I(\theta) = - E[\frac{\partial^2}{\partial \theta^2} logL(x_1,\ldots, x_n \mid \theta)]\]</span></p>
<ul>
<li>e.g., for binomail distribution, <span class="math inline">\(I(\theta)=\frac{n}{\theta(1-\theta)}\)</span>, thus the 95% CI for <span class="math inline">\(\hat{\theta}_{mle}\)</span> is
<span class="math display">\[ \hat{\theta}_{mle} \pm 1.96 \sqrt{\frac{\hat{\theta}_{mle}(1-\hat{\theta}_{mle})}{n}} \]</span></li>
</ul>
<p>which gives us <span class="math inline">\(0.3 \pm 1.96 \times \sqrt{\frac{0.3 \times 0.7}{10}}\)</span>, [0.016, 0.584].</p></li>
</ul>
</div>
<p>How to calculate variance of MLE in R?</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="bayes.html#cb32-1" aria-hidden="true" tabindex="-1"></a>mle<span class="ot">&lt;-</span><span class="fu">optim</span>(<span class="at">par =</span> <span class="fl">0.5</span>, <span class="at">fn=</span>neglogL, <span class="at">method =</span> <span class="st">&quot;Brent&quot;</span>, <span class="at">lower =</span> <span class="dv">0</span>, <span class="at">upper =</span> <span class="dv">1</span>, <span class="at">hessian =</span> <span class="cn">TRUE</span>)</span>
<span id="cb32-2"><a href="bayes.html#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="bayes.html#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="co"># solve(mle$hessian) # to compute the inverse of hessian which is the approximate the variance of theta;</span></span>
<span id="cb32-4"><a href="bayes.html#cb32-4" aria-hidden="true" tabindex="-1"></a>upperbound<span class="ot">&lt;-</span><span class="fl">0.3</span> <span class="sc">+</span> <span class="fl">1.96</span><span class="sc">*</span><span class="fu">sqrt</span>(<span class="fu">solve</span>(mle<span class="sc">$</span>hessian))</span>
<span id="cb32-5"><a href="bayes.html#cb32-5" aria-hidden="true" tabindex="-1"></a>lowerbound<span class="ot">&lt;-</span><span class="fl">0.3</span> <span class="sc">-</span> <span class="fl">1.96</span><span class="sc">*</span><span class="fu">sqrt</span>(<span class="fu">solve</span>(mle<span class="sc">$</span>hessian))</span>
<span id="cb32-6"><a href="bayes.html#cb32-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-7"><a href="bayes.html#cb32-7" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="fu">paste</span>(<span class="st">&quot;95% CI for theta is:&quot;</span>,<span class="fu">round</span>(lowerbound,<span class="dv">3</span>),<span class="st">&quot;-&quot;</span>, <span class="fu">round</span>(upperbound,<span class="dv">3</span>)))</span></code></pre></div>
<pre><code>## [1] &quot;95% CI for theta is: 0.016 - 0.584&quot;</code></pre>
<div class="guidedexercise">
<p><strong>Practice MLE estimation in R (Tutorial Practice)</strong></p>
<p>Suppose we want to estimate the risk of death after a surgery and We assume that every patient has the same risk . We collect data from 100 surgeries and we find that 30 patients died and 70 survived,</p>
<ul>
<li>What is the likelihood function for in this example?</li>
<li>What is the MLE estimator given the observed data?</li>
<li>Can you construct the 95% CI confidence interval of the MLE estimator?</li>
<li>What is you conclusion comparing this estimator to the MLE obtain from the smaller dataset (10 surgeries, 3 patients died and 7 survived)?</li>
</ul>
</div>
</div>
<div id="introduction-to-bayesian-approach" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Introduction to Bayesian approach</h2>
<div id="review-from-session-1" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Review from session 1</h3>
<ul>
<li>In the Bayesian approach, everything that is not data is considered as a parameter</li>
<li>Uncertainty about these parameters is expressed using probability distributions
and probabilistic statements</li>
<li>A prior distribution expresses what is known or believed independently of the data</li>
<li>This prior is updated as data or new evidence is presented</li>
<li>The posterior distribution expresses the updated belief</li>
</ul>
<div class="important">
<p><strong>Recall Bayes theorem</strong></p>
<p>Let <span class="math inline">\(D = \text{patient has disease}\)</span> and <span class="math inline">\(Y = \text{patient has a positive diagnostic test}\)</span>,</p>
<p><span class="math display">\[\begin{aligned}
P(D \mid T) &amp; = \frac{P(T \mid D)P(D)}{P(T)} \\
&amp; = \frac{P(T \mid D)P(D)}{P(T \mid D)P(D) + P(T \mid D^c)P(D^c)}
\end{aligned}\]</span></p>
<ul>
<li><span class="math inline">\(P(T\mid D)\)</span> is the <strong>likelihood</strong> of the outcome (positive test) given the unknown parameter (disease state)</li>
<li><span class="math inline">\(P(D)\)</span> is <strong>pre-test probability</strong> (prior probability) of disease</li>
<li><span class="math inline">\(P(D\mid T)\)</span> is the post-test probability of disease which can be obtained by multiplying the <strong>likelihood</strong> and the <strong>pre-test probabiltiy</strong>.</li>
<li>Here, to calculate <span class="math inline">\(P(D\mid T)\)</span> we need <span class="math inline">\(P(D)\)</span>!</li>
<li>A very sensitive test (e.g., P(TD) = 0.99) can still result in a small post-test probability if the prior probability of disease, <span class="math inline">\(P(D)\)</span>, is low!</li>
</ul>
</div>
<p><strong>The Bayesian approach to estimating parameters stems from Bayes’ theorem for continuous variables:</strong></p>
<p>Let <span class="math inline">\(\theta\)</span> be the parameter of interest and <span class="math inline">\(y\)</span> be the observed data,</p>
<p><span class="math display">\[\begin{aligned}
P(\theta \mid y) &amp; = \frac{P(y \mid \theta)P(\theta)}{P(y)} \\
&amp; = \frac{\text{likelihood of data given parameter} \times \text{prior}}{\text{marginal distribution of data free of the parameter}} \\
&amp; \propto \text{likelihood}(y \mid \theta ) \times \text{prior}(\theta)
\end{aligned}\]</span></p>
<ul>
<li><p><span class="math inline">\(P(y)\)</span> is called a normalizing factor, it’s in place to ensure that <span class="math inline">\(\int P(\theta \mid y) d\theta = 1\)</span>, that is the posterior distribution of <span class="math inline">\(\theta\)</span> is a proper probability distribution with area under the density curve equals to 1.</p></li>
<li><p>Its value is not of interest, unless we are comparing between data models.</p></li>
<li><p>The essence of Bayes theorem only concerns the terms involving the parameter, <span class="math inline">\(\theta\)</span>, hence <span class="math inline">\(P(\theta \mid y) \propto P(y\mid \theta)P(\theta)\)</span>.</p></li>
</ul>
<div class="workedexample">
<p><strong>Estimating a Proportion</strong></p>
<p>Suppose you have observed 6 patients in a Phase I RCT on a given dose of drug,
- 0 out of 6 patients have had an adverse event
- decision to escalate to a higher dose if it’s unlikely that the current dosing results in a true proportion of adverse events above 20% (i.e., given the current data, is there sufficient evidence to infer the true proportion of adverse event is less than 20%, if so we can increase the dose level)</p>
<ul>
<li>This is a classic phase I estimate, under frequentist test (Exact Binomial Test) we have</li>
</ul>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="bayes.html#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">binom.test</span>(<span class="at">x=</span><span class="dv">0</span>, <span class="at">n=</span><span class="dv">6</span>, <span class="at">p =</span> <span class="fl">0.2</span>,</span>
<span id="cb34-2"><a href="bayes.html#cb34-2" aria-hidden="true" tabindex="-1"></a>           <span class="at">alternative =</span> <span class="fu">c</span>(<span class="st">&quot;less&quot;</span>),</span>
<span id="cb34-3"><a href="bayes.html#cb34-3" aria-hidden="true" tabindex="-1"></a>           <span class="at">conf.level =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  0 and 6
## number of successes = 0, number of trials = 6, p-value = 0.2621
## alternative hypothesis: true probability of success is less than 0.2
## 95 percent confidence interval:
##  0.0000000 0.3930378
## sample estimates:
## probability of success 
##                      0</code></pre>
<ul>
<li>The observed proportion <span class="math inline">\(\hat{\theta}=0\)</span> with 95% CI: 0 - 0.39.</li>
<li>How much evidence we have that AE rate is &lt; 20%?</li>
</ul>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="bayes.html#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co">#suppose we observe 0 adverse event out of 14 patients; </span></span>
<span id="cb36-2"><a href="bayes.html#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="co">#the test results below suggest we would reject the null hypothesis;</span></span>
<span id="cb36-3"><a href="bayes.html#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="co">#at 0.05 alpha level and conclude the true AE rate is &lt; 20%;</span></span>
<span id="cb36-4"><a href="bayes.html#cb36-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-5"><a href="bayes.html#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="fu">binom.test</span>(<span class="at">x=</span><span class="dv">0</span>, <span class="at">n=</span><span class="dv">14</span>, <span class="at">p =</span> <span class="fl">0.2</span>,</span>
<span id="cb36-6"><a href="bayes.html#cb36-6" aria-hidden="true" tabindex="-1"></a>           <span class="at">alternative =</span> <span class="fu">c</span>(<span class="st">&quot;less&quot;</span>),</span>
<span id="cb36-7"><a href="bayes.html#cb36-7" aria-hidden="true" tabindex="-1"></a>           <span class="at">conf.level =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>## 
##  Exact binomial test
## 
## data:  0 and 14
## number of successes = 0, number of trials = 14, p-value = 0.04398
## alternative hypothesis: true probability of success is less than 0.2
## 95 percent confidence interval:
##  0.0000000 0.1926362
## sample estimates:
## probability of success 
##                      0</code></pre>
</div>
<p><strong>What would a Bayesian do?</strong></p>
<p>To make probability statements about <span class="math inline">\(\theta\)</span> after observing data <span class="math inline">\(y\)</span>, we need a probability distribution for <span class="math inline">\(\theta\)</span> given <span class="math inline">\(y\)</span> (the posterior distribution).</p>
<p>1.First, we need to specify a prior distribution for <span class="math inline">\(\theta\)</span>, <span class="math inline">\(P(\theta)\)</span>.</p>
<ul>
<li><p>Example 1: We might have no idea about <span class="math inline">\(\theta\)</span> other than that it lies in the interval [0,1] and thus specify a unif(0,1). Let <span class="math inline">\(\theta \sim U(0,1)\)</span>, the prior probability distribution (p.d.f) is
<span class="math display">\[ P(\theta) = \frac{1}{1-0} = 1.\]</span></p></li>
<li><p>Example 2: We might have some knowledge about the range of <span class="math inline">\(\theta\)</span>, say, we are believe <span class="math inline">\(0.05&lt;\theta&lt;0.5\)</span>. We can have
<span class="math display">\[ \theta \sim U(0.05, 0.5)\]</span>
<span class="math display">\[P(\theta) = \frac{1}{0.5-0.05} = 2.22.\]</span></p></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><p>We assume the <span class="math inline">\(P(y \mid \theta)\)</span> follows a binomial distribution, thus the likelihood of the observed data given <span class="math inline">\(\theta\)</span> is
<span class="math display">\[ P(y = 0 \mid \theta) = {6 \choose 0} \theta^0 (1-\theta)^6 = (1-\theta)^6\]</span></p></li>
<li><p>The posterior then becomes (given example prior 1)</p></li>
</ol>
<p><span class="math display">\[\begin{align}
P(\theta \mid y = 0) &amp;= \frac{P(y = 0 \mid \theta) \times P(\theta)}{P(y=0)} \\
&amp; = \frac{(1-\theta)^6 \times 1}{P(y=0)} \\
&amp; = \text{Constant} \times (1-\theta)^6 \\
 &amp; \propto (1-\theta)^6 
\end{align}\]</span></p>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="bayes.html#cb38-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">p_grid =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">1000</span>),</span>
<span id="cb38-2"><a href="bayes.html#cb38-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">y      =</span> <span class="dv">0</span>, </span>
<span id="cb38-3"><a href="bayes.html#cb38-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">n      =</span> <span class="dv">6</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb38-4"><a href="bayes.html#cb38-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">prior      =</span> <span class="fu">dunif</span>(p_grid, <span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb38-5"><a href="bayes.html#cb38-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">likelihood =</span> <span class="fu">dbinom</span>(y, n, p_grid)) <span class="sc">%&gt;%</span> </span>
<span id="cb38-6"><a href="bayes.html#cb38-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">posterior =</span> likelihood <span class="sc">*</span> prior )</span>
<span id="cb38-7"><a href="bayes.html#cb38-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-8"><a href="bayes.html#cb38-8" aria-hidden="true" tabindex="-1"></a>d <span class="sc">%&gt;%</span> <span class="fu">pivot_longer</span>(prior<span class="sc">:</span>posterior) <span class="sc">%&gt;%</span> </span>
<span id="cb38-9"><a href="bayes.html#cb38-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># this line allows us to dictate the order in which the panels will appear</span></span>
<span id="cb38-10"><a href="bayes.html#cb38-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">name =</span> <span class="fu">factor</span>(name, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;prior&quot;</span>, <span class="st">&quot;likelihood&quot;</span>, <span class="st">&quot;posterior&quot;</span>))) <span class="sc">%&gt;%</span> </span>
<span id="cb38-11"><a href="bayes.html#cb38-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> p_grid, <span class="at">y =</span> value, <span class="at">fill =</span> name)) <span class="sc">+</span></span>
<span id="cb38-12"><a href="bayes.html#cb38-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_area</span>(<span class="at">show.legend =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb38-13"><a href="bayes.html#cb38-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;grey&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>)) <span class="sc">+</span></span>
<span id="cb38-14"><a href="bayes.html#cb38-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">facet_wrap</span>(<span class="sc">~</span> name, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>)<span class="sc">+</span></span>
<span id="cb38-15"><a href="bayes.html#cb38-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>()</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-44"></span>
<img src="bayes_bookdown_files/figure-html/unnamed-chunk-44-1.png" alt="Approximate posterior distribution obtained using Bayes' rule with UNIF(0,1) prior. In this example, the normalizaing term P(y=0) is not considered." width="672" />
<p class="caption">
Figure 3.1: Approximate posterior distribution obtained using Bayes’ rule with UNIF(0,1) prior. In this example, the normalizaing term P(y=0) is not considered.
</p>
</div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-45"></span>
<img src="bayes_bookdown_files/figure-html/unnamed-chunk-45-1.png" alt="Approximate posterior distribution obtained using Bayes' rule with UNIF(0.05,0.5) prior. In this example, the normalizaing term P(y=0) is not considered." width="672" />
<p class="caption">
Figure 3.2: Approximate posterior distribution obtained using Bayes’ rule with UNIF(0.05,0.5) prior. In this example, the normalizaing term P(y=0) is not considered.
</p>
</div>
<p><strong>Why is P(y=0) free of <span class="math inline">\(\theta\)</span>?</strong></p>
<ul>
<li>The <strong>law of total probability</strong> for discrete parameter values can be used</li>
<li>Suppose there are two possible values of parameter <span class="math inline">\(\theta\)</span>, 0.5 and 0.1.</li>
<li>Suppose we know the prior distribution of <span class="math inline">\(\theta\)</span>: <span class="math inline">\(P(\theta = 0.5) = 0:8\)</span> and
<span class="math inline">\(P(\theta = 0.1) = 0.2\)</span></li>
<li>Likelihood values are calculated given a known <span class="math inline">\(\theta\)</span>, so then don’t include the parameter <span class="math inline">\(\theta\)</span>.</li>
<li>Call these <span class="math inline">\(P_{0.5} = P(Y = 0 \mid \theta = 0.5)\)</span> and <span class="math inline">\(P_{0.1} = P(Y = 0 \mid \theta = 0.1)\)</span>,</li>
<li>Putting all components together using law of total probability, <span class="math inline">\(P(Y = 0)\)</span> does not involved the unknown <span class="math inline">\(\theta\)</span>
<span class="math display">\[P(Y = 0) = P(Y = 0 \mid \theta = 0.5)P(\theta = 0.5) + P(Y = 0 \mid \theta = 0.1)P(\theta = 0.1)\]</span></li>
</ul>
<p><span class="math display">\[ P(Y = 0) = P_{0.5} \times 0.8 + P_{0.1} \times 0.2 \]</span></p>
<ul>
<li><p>In case of a continuous parameter value, we can obtain <span class="math inline">\(P(y=0)\)</span> by integrating over the space of <span class="math inline">\(\theta\)</span> as following
<span class="math display">\[P(y=0) = \int_{\theta=0}^{\theta=1} P(y=0 \mid \theta) P(\theta) \ d \theta\]</span></p></li>
<li><p>Integrating over <span class="math inline">\(\theta\)</span> is analogous to summing over a set of discrete values of <span class="math inline">\(\theta\)</span>.</p></li>
<li><p>After integration over <span class="math inline">\(\theta\)</span>, <span class="math inline">\(\theta\)</span> is no longer featured in <span class="math inline">\(P(y=0)\)</span>.</p></li>
<li><p>In this example, we have</p></li>
</ul>
<p><span class="math display">\[P(y=0) = \int_{\theta=0}^{\theta=1} P(y=0 \mid \theta) \times \frac{1}{1-0} \ d \theta \]</span>
<span class="math display">\[P(y=0) = \int_{\theta=0}^{\theta=1} P(y=0 \mid \theta) \times \frac{1}{0.5-0.05} \ d \theta \]</span></p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="bayes.html#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Integration in R with one variable;</span></span>
<span id="cb39-2"><a href="bayes.html#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="co">#Unif(0,1);</span></span>
<span id="cb39-3"><a href="bayes.html#cb39-3" aria-hidden="true" tabindex="-1"></a>integrand <span class="ot">&lt;-</span> <span class="cf">function</span>(theta) {(<span class="dv">1</span><span class="sc">-</span>theta)<span class="sc">^</span><span class="dv">6</span>}</span>
<span id="cb39-4"><a href="bayes.html#cb39-4" aria-hidden="true" tabindex="-1"></a>normalizing_constant<span class="ot">&lt;-</span><span class="fu">integrate</span>(integrand, <span class="at">lower =</span> <span class="dv">0</span>, <span class="at">upper =</span> <span class="dv">1</span>)</span>
<span id="cb39-5"><a href="bayes.html#cb39-5" aria-hidden="true" tabindex="-1"></a>normalizing_constant</span></code></pre></div>
<pre><code>## 0.1428571 with absolute error &lt; 0.0000000000000016</code></pre>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="bayes.html#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Unif(0.05,0.5);</span></span>
<span id="cb41-2"><a href="bayes.html#cb41-2" aria-hidden="true" tabindex="-1"></a>integrand2 <span class="ot">&lt;-</span> <span class="cf">function</span>(theta) {((<span class="dv">1</span><span class="sc">-</span>theta)<span class="sc">^</span><span class="dv">6</span>)<span class="sc">/</span>(<span class="fl">0.5-0.05</span>)}</span>
<span id="cb41-3"><a href="bayes.html#cb41-3" aria-hidden="true" tabindex="-1"></a>normalizing_constant2<span class="ot">&lt;-</span><span class="fu">integrate</span>(integrand2, <span class="at">lower =</span> <span class="dv">0</span>, <span class="at">upper =</span> <span class="dv">1</span>)</span>
<span id="cb41-4"><a href="bayes.html#cb41-4" aria-hidden="true" tabindex="-1"></a>normalizing_constant2</span></code></pre></div>
<pre><code>## 0.3174603 with absolute error &lt; 0.0000000000000035</code></pre>
<div class="fold s">

<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="bayes.html#cb43-1" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">p_grid =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">1000</span>),</span>
<span id="cb43-2"><a href="bayes.html#cb43-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">y      =</span> <span class="dv">0</span>, </span>
<span id="cb43-3"><a href="bayes.html#cb43-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">n      =</span> <span class="dv">6</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb43-4"><a href="bayes.html#cb43-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">prior1 =</span> <span class="fu">dunif</span>(p_grid, <span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb43-5"><a href="bayes.html#cb43-5" aria-hidden="true" tabindex="-1"></a>           <span class="at">prior2 =</span> <span class="fu">dunif</span>(p_grid, <span class="fl">0.05</span>, <span class="fl">0.5</span>),</span>
<span id="cb43-6"><a href="bayes.html#cb43-6" aria-hidden="true" tabindex="-1"></a>           <span class="at">likelihood =</span> <span class="fu">dbinom</span>(y, n, p_grid)) <span class="sc">%&gt;%</span> </span>
<span id="cb43-7"><a href="bayes.html#cb43-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">posterior1 =</span> likelihood <span class="sc">*</span> prior1 <span class="sc">/</span> normalizing_constant<span class="sc">$</span>value,</span>
<span id="cb43-8"><a href="bayes.html#cb43-8" aria-hidden="true" tabindex="-1"></a>           <span class="at">posterior2 =</span> likelihood <span class="sc">*</span> prior2 <span class="sc">/</span> normalizing_constant2<span class="sc">$</span>value)</span>
<span id="cb43-9"><a href="bayes.html#cb43-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-10"><a href="bayes.html#cb43-10" aria-hidden="true" tabindex="-1"></a>d <span class="sc">%&gt;%</span> <span class="fu">pivot_longer</span>(posterior1<span class="sc">:</span>posterior2) <span class="sc">%&gt;%</span> </span>
<span id="cb43-11"><a href="bayes.html#cb43-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> p_grid, <span class="at">y =</span> value, <span class="at">group =</span> <span class="fu">as.factor</span>(name))) <span class="sc">+</span></span>
<span id="cb43-12"><a href="bayes.html#cb43-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_area</span>(<span class="fu">aes</span>(<span class="at">fill =</span> name),<span class="at">position=</span><span class="st">&quot;identity&quot;</span>) <span class="sc">+</span></span>
<span id="cb43-13"><a href="bayes.html#cb43-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_fill_manual</span>(<span class="at">name =</span> <span class="st">&quot;Prior&quot;</span>, <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;UNIF(0,1)&quot;</span>,<span class="st">&quot;UNIF(0.05,0.5)&quot;</span>),<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;#d8b365&quot;</span>,  <span class="st">&quot;#5ab4ac&quot;</span>)) <span class="sc">+</span></span>
<span id="cb43-14"><a href="bayes.html#cb43-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fl">0.2</span>, <span class="at">size=</span><span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb43-15"><a href="bayes.html#cb43-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="at">x=</span><span class="fl">0.3</span>, <span class="at">y=</span><span class="dv">6</span>, <span class="at">label=</span> <span class="fu">expression</span>(<span class="fu">paste</span>(theta, <span class="st">&quot;=0.2&quot;</span>)), <span class="at">size =</span> <span class="dv">5</span>) <span class="sc">+</span> </span>
<span id="cb43-16"><a href="bayes.html#cb43-16" aria-hidden="true" tabindex="-1"></a>    <span class="fu">labs</span>(<span class="at">x =</span> <span class="fu">expression</span>(theta), <span class="at">y =</span> <span class="st">&quot;posterior probability density&quot;</span>, <span class="at">title=</span><span class="st">&quot;Posterior distribution given uniform priors and binary data&quot;</span>)<span class="sc">+</span></span>
<span id="cb43-17"><a href="bayes.html#cb43-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>()</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-47"></span>
<img src="bayes_bookdown_files/figure-html/unnamed-chunk-47-1.png" alt="Posterior distribution obtained using Bayes' rule with UNIF(0,1) and UNIF(0.05,0.5) priors" width="672" />
<p class="caption">
Figure 3.3: Posterior distribution obtained using Bayes’ rule with UNIF(0,1) and UNIF(0.05,0.5) priors
</p>
</div>
<div>

<div class="guidedexercise">
<p><strong>Practice posterior estimation with brms package in R (Tutorial Practice)</strong></p>
<blockquote>
<p>we will introduction MCMC in later sessions.</p>
</blockquote>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="bayes.html#cb44-1" aria-hidden="true" tabindex="-1"></a>dat1<span class="ot">&lt;-</span><span class="fu">data.frame</span>(<span class="at">y=</span><span class="fu">rep</span>(<span class="dv">0</span>,<span class="dv">6</span>))</span>
<span id="cb44-2"><a href="bayes.html#cb44-2" aria-hidden="true" tabindex="-1"></a>fit1 <span class="ot">&lt;-</span> <span class="fu">brm</span>(<span class="at">data =</span> dat1, </span>
<span id="cb44-3"><a href="bayes.html#cb44-3" aria-hidden="true" tabindex="-1"></a>      <span class="at">family =</span> <span class="fu">bernoulli</span>(<span class="at">link =</span> <span class="st">&quot;identity&quot;</span>),</span>
<span id="cb44-4"><a href="bayes.html#cb44-4" aria-hidden="true" tabindex="-1"></a>      y <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb44-5"><a href="bayes.html#cb44-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">class =</span> Intercept)),</span>
<span id="cb44-6"><a href="bayes.html#cb44-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">iter =</span> <span class="dv">1000</span> <span class="sc">+</span> <span class="dv">2000</span>, <span class="at">warmup =</span> <span class="dv">1000</span>, <span class="at">chains =</span> <span class="dv">4</span>, <span class="at">cores =</span> <span class="dv">2</span>,</span>
<span id="cb44-7"><a href="bayes.html#cb44-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">seed =</span> <span class="dv">123</span>)</span>
<span id="cb44-8"><a href="bayes.html#cb44-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-9"><a href="bayes.html#cb44-9" aria-hidden="true" tabindex="-1"></a>fit2 <span class="ot">&lt;-</span> <span class="fu">brm</span>(<span class="at">data =</span> dat1, </span>
<span id="cb44-10"><a href="bayes.html#cb44-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">family =</span> <span class="fu">bernoulli</span>(<span class="at">link =</span> <span class="st">&quot;identity&quot;</span>),</span>
<span id="cb44-11"><a href="bayes.html#cb44-11" aria-hidden="true" tabindex="-1"></a>      y <span class="sc">~</span> <span class="dv">1</span>,</span>
<span id="cb44-12"><a href="bayes.html#cb44-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">prior =</span> <span class="fu">c</span>(<span class="fu">prior</span>(<span class="fu">uniform</span>(<span class="fl">0.05</span>, <span class="fl">0.5</span>), <span class="at">class =</span> Intercept)),</span>
<span id="cb44-13"><a href="bayes.html#cb44-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">iter =</span> <span class="dv">1000</span> <span class="sc">+</span> <span class="dv">2000</span>, <span class="at">warmup =</span> <span class="dv">1000</span>, <span class="at">chains =</span> <span class="dv">4</span>,<span class="at">cores =</span> <span class="dv">2</span>,</span>
<span id="cb44-14"><a href="bayes.html#cb44-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">seed =</span> <span class="dv">123</span>)</span>
<span id="cb44-15"><a href="bayes.html#cb44-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-16"><a href="bayes.html#cb44-16" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit1)</span>
<span id="cb44-17"><a href="bayes.html#cb44-17" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit2)</span>
<span id="cb44-18"><a href="bayes.html#cb44-18" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb44-19"><a href="bayes.html#cb44-19" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit1)</span>
<span id="cb44-20"><a href="bayes.html#cb44-20" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit2)</span>
<span id="cb44-21"><a href="bayes.html#cb44-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-22"><a href="bayes.html#cb44-22" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_areas</span>(</span>
<span id="cb44-23"><a href="bayes.html#cb44-23" aria-hidden="true" tabindex="-1"></a>  fit1, </span>
<span id="cb44-24"><a href="bayes.html#cb44-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb44-25"><a href="bayes.html#cb44-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">prob =</span> <span class="fl">0.80</span>, <span class="co"># 80% inner intervals;</span></span>
<span id="cb44-26"><a href="bayes.html#cb44-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">prob_outer =</span> <span class="fl">0.95</span>, <span class="co"># 99% outter intervals;</span></span>
<span id="cb44-27"><a href="bayes.html#cb44-27" aria-hidden="true" tabindex="-1"></a>  <span class="at">point_est =</span> <span class="st">&quot;mean&quot;</span></span>
<span id="cb44-28"><a href="bayes.html#cb44-28" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-29"><a href="bayes.html#cb44-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-30"><a href="bayes.html#cb44-30" aria-hidden="true" tabindex="-1"></a><span class="fu">mcmc_areas</span>(</span>
<span id="cb44-31"><a href="bayes.html#cb44-31" aria-hidden="true" tabindex="-1"></a>  fit2, </span>
<span id="cb44-32"><a href="bayes.html#cb44-32" aria-hidden="true" tabindex="-1"></a>  <span class="at">pars =</span> <span class="fu">c</span>(<span class="st">&quot;Intercept&quot;</span>),</span>
<span id="cb44-33"><a href="bayes.html#cb44-33" aria-hidden="true" tabindex="-1"></a>  <span class="at">prob =</span> <span class="fl">0.80</span>, <span class="co"># 80% inner intervals;</span></span>
<span id="cb44-34"><a href="bayes.html#cb44-34" aria-hidden="true" tabindex="-1"></a>  <span class="at">prob_outer =</span> <span class="fl">0.95</span>, <span class="co"># 99% outter intervals;</span></span>
<span id="cb44-35"><a href="bayes.html#cb44-35" aria-hidden="true" tabindex="-1"></a>  <span class="at">point_est =</span> <span class="st">&quot;mean&quot;</span></span>
<span id="cb44-36"><a href="bayes.html#cb44-36" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb44-37"><a href="bayes.html#cb44-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-38"><a href="bayes.html#cb44-38" aria-hidden="true" tabindex="-1"></a><span class="fu">hypothesis</span>(fit1, <span class="st">&#39;Intercept &lt; 0.2&#39;</span>)</span>
<span id="cb44-39"><a href="bayes.html#cb44-39" aria-hidden="true" tabindex="-1"></a><span class="fu">hypothesis</span>(fit2, <span class="st">&#39;Intercept &lt; 0.2&#39;</span>)</span></code></pre></div>
</div>
</div>
<div id="the-beta-binomial-model" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> The Beta-binomial model</h3>
<ul>
<li>With a single sample of <span class="math inline">\(n\)</span> binary outcomes, we have one unknown parameter: <span class="math inline">\(\theta\)</span> and <span class="math inline">\(0 \leq \theta \leq 1\)</span>.</li>
<li>We need a prior distribution for <span class="math inline">\(\theta\)</span> (e.g., proportion, risk, probability of event etc): <span class="math inline">\(P(\theta)\)</span>
<ul>
<li>To express indifference between all values of <span class="math inline">\(\theta\)</span>, we can use a uniform distribution on <span class="math inline">\(\theta\)</span>, as we did in the previous example</li>
<li>To express belief (e.g. based on external evidence) that some values of <span class="math inline">\(\theta\)</span> are more likely that others, it is convenient to use a <strong>beta distribution</strong></li>
<li>This has two parameters, often labelled as <span class="math inline">\(\alpha\)</span> (also written as a) and <span class="math inline">\(\beta\)</span> (also written as b), which we can choose to represent the strength of the external evidence</li>
<li>If a parameter has a Beta(a,b) distribution, then the prior mean is
<span class="math display">\[\frac{a}{a+b}\]</span></li>
<li>The beta distribution prior for the binomial is useful for illustrating how the Bayesian approach combines prior information and new data</li>
</ul></li>
</ul>
<div class="important">
<p><strong>Beta-binomial model</strong></p>
<ul>
<li>Recall the likelihood for a binomial outcome of x successes in n trials,</li>
</ul>
<p><span class="math display">\[ P(x \mid \theta) \propto \theta^x (1-\theta)^{n-x}\]</span></p>
<ul>
<li>The <span class="math inline">\(Beta(\alpha,\beta)\)</span> prior has the same functional form for <span class="math inline">\(\theta\)</span>,</li>
</ul>
<p><span class="math display">\[ P( \theta) \propto \theta^{\alpha-1} (1-\theta)^{\beta-1}\]</span></p>
<ul>
<li>We find the posterior as</li>
</ul>
<p><span class="math display">\[\begin{align}
P(\theta \mid x) &amp; \propto P(x \mid \theta) \times P( \theta) \\
&amp; \propto \theta^x (1-\theta)^{n-x} \times \theta^{\alpha-1} (1-\theta)^{\beta-1} \\
&amp;  \propto \theta^{x+\alpha-1}  (1-\theta)^{n-x+\beta-1}
\end{align}\]</span></p>
<ul>
<li><p>Thus, comparing to the <span class="math inline">\(Beta(\alpha,\beta)\)</span> prior, the posterior just changes the exponents by adding <strong>x and n-x</strong>, respectively.</p>
<ul>
<li>Comparing to the prior, make two changes to get the posterior:
<ol style="list-style-type: decimal">
<li><span class="math inline">\(a \rightarrow a+x\)</span>, [a + number of events]</li>
<li><span class="math inline">\(b \rightarrow b+(n-x)\)</span>, [b + number of non-events]</li>
</ol></li>
<li>Quite simply, when <span class="math inline">\(x\)</span> events have been observed in n subjects, the prior</li>
</ul>
<p><span class="math display">\[ \theta \sim Beta(\alpha, \beta) \]</span></p>
<ul>
<li>gives the posterior</li>
</ul>
<p><span class="math display">\[ \theta \mid x \sim Beta(\alpha+x, \beta+n-x) \]</span></p></li>
<li><p>The prior and posterior are both <strong>beta distributions!</strong></p></li>
</ul>
</div>
<p><strong>Interpretation of Beta Prior</strong></p>
<ul>
<li>Suppose we start with a beta prior with small parameters</li>
</ul>
<p><span class="math display">\[ \theta \sim Beta(0.001, 0.001) \]</span></p>
<ul>
<li>Observe x events in n trials, the posterior</li>
</ul>
<p><span class="math display">\[ \theta \mid x \sim Beta(0.001+x, 0.001+n-x) \approx Beta(x,n-x)\]</span></p>
<ul>
<li><p>Posterior mean of <span class="math inline">\(\theta \approx \frac{x}{n}\)</span>, the equivalent to the MLE based only on the data</p></li>
<li><p>Interpretation of the <span class="math inline">\(Beta(\alpha,\beta)\)</span> prior.</p>
<ul>
<li>Like having seen <span class="math inline">\(\alpha\)</span> events and <span class="math inline">\(\beta\)</span> non events in a sample size of <span class="math inline">\(\alpha + \beta\)</span></li>
<li>Strength of prior information equivalent to prior “sample size” <span class="math inline">\(\alpha + \beta\)</span></li>
<li>Prior mean = <span class="math inline">\(\frac{\alpha}{\alpha + \beta}\)</span></li>
</ul></li>
</ul>
<div class="workedexample">
<p>Consider Beta(3,7)and Beta(12,28) priors</p>
<ul>
<li>Gold line: prior belief that assumes approximately 3 events in 10 subjects</li>
<li>Blue line: prior belief that assumes approximately 12 events in 40(=12+28) subjects</li>
</ul>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-49-1.png" width="672" /></p>
</div>
<div class="guidedexercise">
<p><strong>Plot Beta densities in R (Tutorial Practice)</strong> Try plotting Beta(2,8), Beta(8,2), and Beta(8,8). Example R code provided below.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="bayes.html#cb45-1" aria-hidden="true" tabindex="-1"></a>a<span class="ot">&lt;-</span><span class="dv">2</span></span>
<span id="cb45-2"><a href="bayes.html#cb45-2" aria-hidden="true" tabindex="-1"></a>b<span class="ot">&lt;-</span><span class="dv">2</span></span>
<span id="cb45-3"><a href="bayes.html#cb45-3" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">theta =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">0</span>, <span class="at">to =</span> <span class="dv">1</span>, <span class="at">length.out =</span> <span class="dv">101</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb45-4"><a href="bayes.html#cb45-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">priorDensity =</span> <span class="fu">dbeta</span>(theta, <span class="at">shape1 =</span> a,<span class="at">shape2 =</span> b))</span>
<span id="cb45-5"><a href="bayes.html#cb45-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-6"><a href="bayes.html#cb45-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(d, <span class="fu">aes</span>(theta, priorDensity))<span class="sc">+</span></span>
<span id="cb45-7"><a href="bayes.html#cb45-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>()<span class="sc">+</span></span>
<span id="cb45-8"><a href="bayes.html#cb45-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="fu">expression</span>(theta))<span class="sc">+</span></span>
<span id="cb45-9"><a href="bayes.html#cb45-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="fu">expression</span>(<span class="fu">p</span>(theta)))<span class="sc">+</span></span>
<span id="cb45-10"><a href="bayes.html#cb45-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="fu">paste0</span>(<span class="st">&quot;Beta distribution with &quot;</span>, <span class="st">&quot;a = &quot;</span>,a,<span class="st">&quot;; b = &quot;</span>,b))<span class="sc">+</span></span>
<span id="cb45-11"><a href="bayes.html#cb45-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
</div>
<p><strong>Summarizing Posterior Distribution</strong></p>
<ul>
<li>Since we know the form of the posterior distribution, we can easily calculate functions such as:
<ol style="list-style-type: decimal">
<li>Posterior mean <span class="math inline">\(E(\theta) = \frac{\alpha+x}{\alpha + \beta+n}\)</span></li>
<li>95% Credible intervals (we will talk more about them next week)</li>
<li><span class="math inline">\(P(\theta &lt; 0.2)\)</span>, <span class="math inline">\(P(\theta &lt; 0.5)\)</span>, <span class="math inline">\(P(0.4&lt; \theta &lt; 0.6)\)</span>, etc, which can be directly used to make probabilistic statement about the <span class="math inline">\(\theta\)</span>. E.g., the probability of the posterior adverse event rate &lt; 0.2 is about 0.95.</li>
</ol></li>
<li>Generate informative plots for assessing priors and posteriors. All this can easily be done using R.</li>
</ul>
<div class="guidedexercise">
<p><strong>Beta densities posterior summary in R (Tutorial Practice)</strong> Suppose we observe 1 adverse events among 10 patients and we assume the prior distribution of adverse event proportion <span class="math inline">\(\theta \sim Beta(1,1)\)</span>.</p>
<ul>
<li>What is the posterior Beta distribution of <span class="math inline">\(\theta\)</span>?</li>
<li>What is the posterior mean Beta distribution of <span class="math inline">\(\theta\)</span>?</li>
<li>What is the posterior probability <span class="math inline">\(P(\theta&lt;0.2)\)</span>?</li>
</ul>
</div>
<p><strong>Data overwhelming the prior</strong></p>
<ul>
<li>The posterior for the beta-binomial model after seeing x events in n trials is <span class="math inline">\(\theta \mid x ~ Beta(\alpha + x, \beta + n - x)\)</span> with posterior mean as</li>
</ul>
<p><span class="math display">\[E(\theta \mid x) = \frac{\alpha + x}{\alpha + \beta + n}\]</span></p>
<ul>
<li><p>In <span class="math inline">\(n \gg \alpha + \beta\)</span> and <span class="math inline">\(x \gg \alpha\)</span> (sample size and number of events is large), recall when using prior <span class="math inline">\(Beta(0.001, 0.001)\)</span>,
<span class="math display">\[ E(\theta \mid x) = \frac{\alpha + x}{\alpha + \beta + n} \approx \frac{x}{n}\]</span></p></li>
<li><p>Here, prior is of little importance!</p></li>
</ul>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-51-1.png" width="768" /></p>
<p><strong>A Beta(1,1) is Unif(0,1)</strong></p>
<ul>
<li>When <span class="math inline">\(\alpha = \beta = 1\)</span>, <span class="math inline">\(P(\theta) \propto \theta^{1-1}(1-\theta)^{1-1} = 1\)</span>, which is the probability density of a unif(0,1).</li>
</ul>
<p><strong>Posterior mean as a weighted average</strong></p>
<ul>
<li>The posterior mean is</li>
</ul>
<p><span class="math display">\[\begin{align}
E(\theta \mid x) &amp; = \frac{\alpha + x}{\alpha + \beta + n} \\
&amp; = \frac{\alpha }{\alpha + \beta + n} + \frac{x }{\alpha + \beta + n}\\
&amp; = \Big( \frac{\alpha+ \beta }{\alpha + \beta + n} \Big) \times \Big( \frac{\alpha }{\alpha + \beta} \Big) + \Big( \frac{n }{\alpha + \beta + n} \Big) \times \Big( \frac{x }{n} \Big) \\
&amp; = w \times \Big( \frac{\alpha }{\alpha + \beta} \Big) + (1-w) \times \Big( \frac{x }{n} \Big) \\
&amp; = w \times (\text{prior mean}) + (1-w) \times (\text{sample estimate})
\end{align}\]</span></p>
<ul>
<li><p>Where <span class="math inline">\(w\)</span> is the ratio of the “prior sample size” to the “total sample size” <span class="math display">\[ w = \frac{\alpha+ \beta }{\alpha + \beta + n}.\]</span></p></li>
<li><p>This is a common theme in Bayesian models with actual prior information</p></li>
<li><p>The posterior distribution will lie between the prior and likelihood</p></li>
<li><p>The posterior mean is a weighted average of the prior mean and data-based estimate</p></li>
<li><p><strong>As the sample size increases, the contribution of the prior diminishes</strong></p></li>
</ul>
</div>
<div id="the-normal-normal-model" class="section level3" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> The Normal-normal model</h3>
</div>
<div id="r-session-information-2" class="section level3 unnumbered">
<h3>R Session information</h3>
<pre><code>## R version 4.0.5 (2021-03-31)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 19042)
## 
## Matrix products: 
## 
## locale:
## [1] LC_COLLATE=English_Canada.1252  LC_CTYPE=English_Canada.1252   
## [3] LC_MONETARY=English_Canada.1252 LC_NUMERIC=C                   
## [5] LC_TIME=English_Canada.1252    
## 
## attached base packages:
## [1] grid      stats     graphics  grDevices utils     datasets  methods  
## [8] base     
## 
## other attached packages:
##  [1] bayesplot_1.8.1     ggmcmc_1.5.1.1      truncnorm_1.0-8    
##  [4] ggpubr_0.4.0        tweenr_1.0.2        gganimate_1.0.7    
##  [7] VennDiagram_1.7.1   futile.logger_1.4.3 brms_2.16.3        
## [10] Rcpp_1.0.7          forcats_0.5.1       stringr_1.4.0      
## [13] dplyr_1.0.7         purrr_0.3.4         readr_2.1.1        
## [16] tidyr_1.1.4         tibble_3.1.6        ggplot2_3.3.5      
## [19] tidyverse_1.3.1</code></pre>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="prob.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="Prior.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": "twitter"
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>

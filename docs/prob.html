<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Session 2 Probability, random variables and distributions | HAD5314H - Applied Bayesian Methods in Clinical Epidemiology and Health Care Research</title>
  <meta name="description" content="Course notes for HAD5314H Winter 2022" />
  <meta name="generator" content="bookdown 0.22.2 and GitBook 2.6.7" />

  <meta property="og:title" content="Session 2 Probability, random variables and distributions | HAD5314H - Applied Bayesian Methods in Clinical Epidemiology and Health Care Research" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://kuan-liu.github.io/bayes_bookdown/" />
  
  <meta property="og:description" content="Course notes for HAD5314H Winter 2022" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Session 2 Probability, random variables and distributions | HAD5314H - Applied Bayesian Methods in Clinical Epidemiology and Health Care Research" />
  
  <meta name="twitter:description" content="Course notes for HAD5314H Winter 2022" />
  

<meta name="author" content="Kuan Liu   Institute of Health Policy, Management and Evaluation   University of Toronto" />


<meta name="date" content="2022-01-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="lab1-getting-started-with-r-rstudio.html"/>
<link rel="next" href="bayes.html"/>
<script src="libs/header-attrs-2.9/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">HAD5314H - Winter 2022 </a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>University of Toronto Statement of Acknowledgment of Traditional Land</a></li>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html"><i class="fa fa-check"></i>Course Syllabus</a>
<ul>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html#course-info"><i class="fa fa-check"></i>Course Info</a></li>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html#course-description"><i class="fa fa-check"></i>Course Description</a></li>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html#course-textbook-and-structure"><i class="fa fa-check"></i>Course Textbook and Structure</a></li>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html#calendar-and-outline"><i class="fa fa-check"></i>Calendar and Outline</a></li>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html#accessibility-and-accommodations"><i class="fa fa-check"></i>Accessibility and Accommodations</a></li>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html#academic-integrity"><i class="fa fa-check"></i>Academic Integrity</a></li>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html#key-resources-and-supports-for-dslph-graduate-students"><i class="fa fa-check"></i>Key Resources and Supports for DSLPH Graduate Students</a></li>
<li class="chapter" data-level="" data-path="course-syllabus.html"><a href="course-syllabus.html#license"><i class="fa fa-check"></i>License</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="into.html"><a href="into.html"><i class="fa fa-check"></i><b>1</b> Introduction to the course</a>
<ul>
<li class="chapter" data-level="1.1" data-path="into.html"><a href="into.html#about-me"><i class="fa fa-check"></i><b>1.1</b> About me</a></li>
<li class="chapter" data-level="1.2" data-path="into.html"><a href="into.html#syllabus"><i class="fa fa-check"></i><b>1.2</b> Syllabus</a></li>
<li class="chapter" data-level="1.3" data-path="into.html"><a href="into.html#some-history"><i class="fa fa-check"></i><b>1.3</b> Some history</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="into.html"><a href="into.html#bayesian-history"><i class="fa fa-check"></i><b>1.3.1</b> Bayesian history</a></li>
<li class="chapter" data-level="1.3.2" data-path="into.html"><a href="into.html#history-of-this-course"><i class="fa fa-check"></i><b>1.3.2</b> History of this course</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="into.html"><a href="into.html#thinking-like-a-bayesian-using-the-concept-of-probability"><i class="fa fa-check"></i><b>1.4</b> Thinking like a Bayesian using the concept of probability</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="into.html"><a href="into.html#probability-is-not-unitary"><i class="fa fa-check"></i><b>1.4.1</b> Probability is not unitary</a></li>
<li class="chapter" data-level="1.4.2" data-path="into.html"><a href="into.html#bayes-rule"><i class="fa fa-check"></i><b>1.4.2</b> Bayes’ Rule</a></li>
<li class="chapter" data-level="1.4.3" data-path="into.html"><a href="into.html#the-scientific-method-in-steps"><i class="fa fa-check"></i><b>1.4.3</b> The Scientific Method in steps</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html"><i class="fa fa-check"></i>Lab1 Getting started with R &amp; Rstudio</a>
<ul>
<li class="chapter" data-level="1.5" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#r-and-rstudio-installation"><i class="fa fa-check"></i><b>1.5</b> R and Rstudio Installation</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#windows-operating-system"><i class="fa fa-check"></i><b>1.5.1</b> Windows operating system</a></li>
<li class="chapter" data-level="1.5.2" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#macos-operating-system"><i class="fa fa-check"></i><b>1.5.2</b> macOS operating system</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#r-packages"><i class="fa fa-check"></i><b>1.6</b> R Packages</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#bayesian-analysis-in-r-using-brms-package"><i class="fa fa-check"></i><b>1.6.1</b> Bayesian Analysis in R using brms package</a></li>
</ul></li>
<li class="chapter" data-level="1.7" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#working-in-rstudio"><i class="fa fa-check"></i><b>1.7</b> Working in Rstudio</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#rstudio-layout"><i class="fa fa-check"></i><b>1.7.1</b> Rstudio layout</a></li>
<li class="chapter" data-level="1.7.2" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#customization"><i class="fa fa-check"></i><b>1.7.2</b> Customization</a></li>
<li class="chapter" data-level="1.7.3" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#working-directory"><i class="fa fa-check"></i><b>1.7.3</b> Working directory</a></li>
<li class="chapter" data-level="1.7.4" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#getting-help-with-r"><i class="fa fa-check"></i><b>1.7.4</b> Getting help with R</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#basic-r-a-crash-introduction"><i class="fa fa-check"></i><b>1.8</b> Basic R (a crash introduction)</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#arithmetic"><i class="fa fa-check"></i><b>1.8.1</b> Arithmetic</a></li>
<li class="chapter" data-level="1.8.2" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#vectors"><i class="fa fa-check"></i><b>1.8.2</b> Vectors</a></li>
<li class="chapter" data-level="1.8.3" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#data-frame---the-titanic-dataset"><i class="fa fa-check"></i><b>1.8.3</b> Data frame - The Titanic dataset</a></li>
<li class="chapter" data-level="1.8.4" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#simple-plots"><i class="fa fa-check"></i><b>1.8.4</b> Simple plots</a></li>
<li class="chapter" data-level="" data-path="lab1-getting-started-with-r-rstudio.html"><a href="lab1-getting-started-with-r-rstudio.html#r-session-information"><i class="fa fa-check"></i>R Session information</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="prob.html"><a href="prob.html"><i class="fa fa-check"></i><b>2</b> Probability, random variables and distributions</a>
<ul>
<li class="chapter" data-level="2.1" data-path="prob.html"><a href="prob.html#introduction-to-set-theory"><i class="fa fa-check"></i><b>2.1</b> Introduction to Set Theory</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="prob.html"><a href="prob.html#composition-of-events"><i class="fa fa-check"></i><b>2.1.1</b> Composition of events</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="prob.html"><a href="prob.html#probability-rules"><i class="fa fa-check"></i><b>2.2</b> Probability Rules</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="prob.html"><a href="prob.html#simple-rules"><i class="fa fa-check"></i><b>2.2.1</b> Simple Rules</a></li>
<li class="chapter" data-level="2.2.2" data-path="prob.html"><a href="prob.html#conditional-probability"><i class="fa fa-check"></i><b>2.2.2</b> Conditional Probability</a></li>
<li class="chapter" data-level="2.2.3" data-path="prob.html"><a href="prob.html#summary-of-probability-rules"><i class="fa fa-check"></i><b>2.2.3</b> Summary of Probability Rules</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="prob.html"><a href="prob.html#discrete-random-variables"><i class="fa fa-check"></i><b>2.3</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="prob.html"><a href="prob.html#introduction-to-discrete-random-variables"><i class="fa fa-check"></i><b>2.3.1</b> Introduction to Discrete Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="prob.html"><a href="prob.html#common-discrete-distributions"><i class="fa fa-check"></i><b>2.4</b> Common Discrete Distributions</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="prob.html"><a href="prob.html#binomial-distribution"><i class="fa fa-check"></i><b>2.4.1</b> Binomial Distribution</a></li>
<li class="chapter" data-level="2.4.2" data-path="prob.html"><a href="prob.html#poisson-distribution"><i class="fa fa-check"></i><b>2.4.2</b> Poisson Distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="prob.html"><a href="prob.html#continuous-random-variables"><i class="fa fa-check"></i><b>2.5</b> Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="prob.html"><a href="prob.html#uniform01-distribution"><i class="fa fa-check"></i><b>2.5.1</b> Uniform(0,1) Distribution</a></li>
<li class="chapter" data-level="2.5.2" data-path="prob.html"><a href="prob.html#exponential-distribution"><i class="fa fa-check"></i><b>2.5.2</b> Exponential Distribution</a></li>
<li class="chapter" data-level="2.5.3" data-path="prob.html"><a href="prob.html#normal-distribution"><i class="fa fa-check"></i><b>2.5.3</b> Normal Distribution</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="prob.html"><a href="prob.html#r-quick-reference"><i class="fa fa-check"></i><b>2.6</b> R Quick Reference</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="bayes.html"><a href="bayes.html"><i class="fa fa-check"></i><b>3</b> Bayesian inference</a>
<ul>
<li class="chapter" data-level="3.1" data-path="bayes.html"><a href="bayes.html#priors"><i class="fa fa-check"></i><b>3.1</b> Priors</a></li>
<li class="chapter" data-level="3.2" data-path="bayes.html"><a href="bayes.html#posterior"><i class="fa fa-check"></i><b>3.2</b> Posterior</a></li>
<li class="chapter" data-level="3.3" data-path="bayes.html"><a href="bayes.html#prediction"><i class="fa fa-check"></i><b>3.3</b> Prediction</a></li>
<li class="chapter" data-level="3.4" data-path="bayes.html"><a href="bayes.html#decision-theory"><i class="fa fa-check"></i><b>3.4</b> Decision theory</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="Prior.html"><a href="Prior.html"><i class="fa fa-check"></i><b>4</b> Considering Prior Distributions</a></li>
<li class="chapter" data-level="5" data-path="BayesReg.html"><a href="BayesReg.html"><i class="fa fa-check"></i><b>5</b> Bayesian Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="BayesReg.html"><a href="BayesReg.html#normal-models-and-linear-regression"><i class="fa fa-check"></i><b>5.1</b> Normal Models and Linear Regression</a></li>
<li class="chapter" data-level="5.2" data-path="BayesReg.html"><a href="BayesReg.html#hierarchical-models-and-convergence"><i class="fa fa-check"></i><b>5.2</b> Hierarchical models and convergence</a></li>
<li class="chapter" data-level="5.3" data-path="BayesReg.html"><a href="BayesReg.html#models-for-binary-data"><i class="fa fa-check"></i><b>5.3</b> Models for Binary Data</a></li>
<li class="chapter" data-level="5.4" data-path="BayesReg.html"><a href="BayesReg.html#models-for-count-data"><i class="fa fa-check"></i><b>5.4</b> Models for Count Data</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a> <a href="https://www.kuan-liu.com/" target="blank">Developed by Kuan Liu</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">HAD5314H - Applied Bayesian Methods in Clinical Epidemiology and Health Care Research</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="prob" class="section level1" number="2">
<h1><span class="header-section-number">Session 2</span> Probability, random variables and distributions</h1>
<div id="introduction-to-set-theory" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Introduction to Set Theory</h2>
<p>Before we jump into probability, it is useful to review a little bit of set theory.</p>
<p>Events are properties of a particular outcome. For a coin flip, the event “Heads” would be the event that a heads was flipped. For the single roll of a six-sided die, a possible event might be that the result is even. For the NAU student, we might be interested in the event that the student is a biology student. A second event of interest might be if the student is an undergraduate.</p>
<p>1.1.1 Venn Diagrams</p>
<p>Let <span class="math inline">\(S\)</span> be the set of all outcomes of my random trial. Suppose I am interested in two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. The traditional way of representing these events is using a Venn diagram.</p>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p>For example, suppose that my random experiment is rolling a fair 6-sided die once. The possible outcomes are <span class="math inline">\(S=\{1,2,3,4,5,6\}\)</span>. Suppose I then define events <span class="math inline">\(A=\)</span> roll is odd and <span class="math inline">\(B=\)</span> roll is 5 or greater. In this case our picture is:</p>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<p>All of our possible events are present, and distributed among our possible events.</p>
<div id="composition-of-events" class="section level3" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Composition of events</h3>
<p>I am often interested in discussing the composition of two events and we give the common set operations below.</p>
<ul>
<li><strong>Union:</strong> Denote the event that either <span class="math inline">\(A\)</span> or <span class="math inline">\(B\)</span> occurs as <span class="math inline">\(A\cup B\)</span>.</li>
</ul>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<ul>
<li><strong>Intersection:</strong> Denote the event that <strong>both</strong> <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> occur as <span class="math inline">\(A\cap B\)</span></li>
</ul>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<ul>
<li><strong>Complement:</strong> Denote the event that <span class="math inline">\(A\)</span> does not occur as <span class="math inline">\(\bar{A}\)</span> or <span class="math inline">\(A^{C}\)</span> (different people use different notations)</li>
</ul>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p><strong>Definition:</strong> Two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are said to be <strong>mutually exclusive</strong> (or <strong>disjoint</strong>) if the occurrence of one event precludes the occurrence of the other. For example, on a single roll of a die, a two and a five cannot both come up. For a second example, define <span class="math inline">\(A\)</span> to be the event that the die is even, and <span class="math inline">\(B\)</span> to be the event that the die comes up as a <span class="math inline">\(5\)</span>.</p>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
</div>
</div>
<div id="probability-rules" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Probability Rules</h2>
<div id="simple-rules" class="section level3" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Simple Rules</h3>
<p>We now take our Venn diagrams and use them to understand the rules of probability. The underlying idea that we will use is the the probability of an event is the area in the Venn diagram.</p>
<p><strong>Definition:</strong> The <strong>probability</strong> is the proportion of times an event occurs in many repeated trials of a random phenomenon. In other words, it is the long-term relative frequency.</p>
<p><strong>Rule:</strong> <em>For any event <span class="math inline">\(A\)</span> the probability of the event <span class="math inline">\(P(A)\)</span> satisfies <span class="math inline">\(0\leq P(A) \leq 1\)</span>. That is to say, the probability of any event will always lie in the interval <span class="math inline">\([0,1]\)</span>.</em></p>
<p>Because <span class="math inline">\(S\)</span> is the set of all events that might occur, the area of our bounding rectangle will be <span class="math inline">\(1\)</span> and the probability of event <span class="math inline">\(A\)</span> occurring will be represented by the area in the circle <span class="math inline">\(A\)</span>.</p>
<p><strong>Rule:</strong> <em>The probability of the set of all events (<span class="math inline">\(S\)</span>) is always 1. That is, <span class="math inline">\(P(S) = 1\)</span>.</em></p>
<p><strong>General Addition Rule:</strong> <span class="math inline">\(P(A\cup B)=P(A)+P(B)-P(A\cap B)\)</span></p>
<p>The reason behind this fact is that if there is if <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are not disjoint, then some area is added twice when I calculate <span class="math inline">\(P\left(A\right)+P\left(B\right)\)</span>. To account for this, I simply subtract off the area that was double counted.</p>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
<p><strong>Rule:</strong> <em>If two events are mutually exclusive, then <span class="math inline">\(P(A\cup B)=P(A)+P(B)\)</span></em></p>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
<p><strong>Example</strong>. Let <span class="math inline">\(R\)</span> be the sum of two different colored dice. Suppose we are interested in <span class="math inline">\(P(R \le 4)\)</span>. Notice that the pair of dice can fall 36 different ways (6 ways for the first die and six for the second results in 6x6 possible outcomes, and each way has equal probability <span class="math inline">\(1/36\)</span>. Because the dice cannot simultaneously sum to <span class="math inline">\(2\)</span> and to <span class="math inline">\(3\)</span>, we could write
<span class="math display">\[\begin{aligned} P(R \le 4 )   
  &amp;=    P(R=2)+P(R=3)+P(R=4) \\
    &amp;=  P(\left\{ 1,1\right\} )+P(\left\{ 1,2\right\} \mathrm{\textrm{ or }}\left\{ 2,1\right\} )+P(\{1,3\}\textrm{ or }\{2,2\}\textrm{ or }\{3,1\}) \\
    &amp;=  \frac{1}{36}+\frac{2}{36}+\frac{3}{36} \\
    &amp;=  \frac{6}{36} \\
    &amp;=  \frac{1}{6} \end{aligned}\]</span></p>
<p><strong>Complement Rule:</strong> <span class="math inline">\(P(A)+P(A^c)=1\)</span></p>
<p>This rule follows from the partitioning of the set of all events (<span class="math inline">\(S\)</span>) into two disjoint sets, <span class="math inline">\(A\)</span> and <span class="math inline">\(A^c\)</span>. We learned above that <span class="math inline">\(A \cup A^c = S\)</span> and that <span class="math inline">\(P(S) = 1\)</span>. Combining those statements, we obtain the complement rule.</p>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
<p><strong>Completeness Rule:</strong> <span class="math inline">\(P(A)=P(A\cap B)+P(A\cap B^c)\)</span></p>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
<p>This identity is just breaking the event <span class="math inline">\(A\)</span> into two disjoint pieces.</p>
</div>
<div id="conditional-probability" class="section level3" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Conditional Probability</h3>
<p>We are given the following data about insurance claims. Notice that the data is given as <span class="math inline">\(P(\;Category\;\cap\;PolicyType\;)\)</span> which is apparent because the sum of all the elements in the table is <span class="math inline">\(100\%\)</span></p>
<table>
<thead>
<tr class="header">
<th align="right"><span class="math inline">\(\,\)</span></th>
<th align="center">Fire</th>
<th align="center">Auto</th>
<th align="center">Other</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><strong>Fraudulant</strong></td>
<td align="center">6%</td>
<td align="center">1%</td>
<td align="center">3%</td>
</tr>
<tr class="even">
<td align="right"><strong>non-Fraudulant</strong></td>
<td align="center">14%</td>
<td align="center">29%</td>
<td align="center">47%</td>
</tr>
</tbody>
</table>
<p>Summing across the rows and columns, we can find the probabilities of for each category and policy type.</p>
<table>
<thead>
<tr class="header">
<th align="right"><span class="math inline">\(\,\)</span></th>
<th align="center">Fire</th>
<th align="center">Auto</th>
<th align="center">Other</th>
<th align="center"><span class="math inline">\(\,\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><strong>Fraudulant</strong></td>
<td align="center">6%</td>
<td align="center">1%</td>
<td align="center">3%</td>
<td align="center"><strong>10%</strong></td>
</tr>
<tr class="even">
<td align="right"><strong>non-Fraudulant</strong></td>
<td align="center">14%</td>
<td align="center">29%</td>
<td align="center">47%</td>
<td align="center"><strong>90%</strong></td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\(\,\)</span></td>
<td align="center"><strong>20%</strong></td>
<td align="center"><strong>30%</strong></td>
<td align="center"><strong>50%</strong></td>
<td align="center"><strong>100%</strong></td>
</tr>
</tbody>
</table>
<p>It is clear that fire claims are more likely fraudulent than auto or other claims. In fact, the proportion of fraudulent claims, given that the claim is against a fire policy is
<span class="math display">\[\begin{aligned}
P(\textrm{ Fraud }|\textrm{ FirePolicy })   &amp;=  \frac{\textrm{proportion of claims that are fire policies and are fraudulent}}{\textrm{proportion of fire claims}} \\
    &amp;=  \frac{6\%}{20\%}\\
    &amp; \\
    &amp;=  0.3
    \end{aligned}\]</span></p>
<p>In general we define conditional probability (assuming <span class="math inline">\(P(B) \ne 0\)</span>) as
<span class="math display">\[P(A|B)=\frac{P(A\cap B)}{P(B)}\]</span>
which can also be rearranged to show
<span class="math display">\[\begin{aligned}
P(A\cap B)  &amp;=  P(A\,|\,B)\,P(B) \\
              &amp;=    P(B\,|\,A)\,P(A)
\end{aligned}\]</span>
Because the order doesn’t matter and <span class="math inline">\(P\left(A\cap B\right)=P\left(B\cap A\right)\)</span>.</p>
<p>Using this rule, we might calculate the probability that a claim is an Auto policy given that it is not fraudulent.
<span class="math display">\[\begin{aligned}
P\left(\,Auto\;|\;NotFraud\,\right) &amp;= \frac{P\left(\,Auto\;\cap\;NotFraud\right)}{P\left(\,NotFraud\,\right)} \\
    &amp;=  \frac{0.29}{0.9} \\
    &amp;   \\
    &amp;=  0.3\bar{2}
    \end{aligned}\]</span></p>
<p><strong>Definition:</strong> Two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are said to be <strong>independent</strong> if <span class="math inline">\(P(A\cap B)=P(A)P(B)\)</span>.</p>
<p>What independence is saying that knowing the outcome of event <span class="math inline">\(A\)</span> doesn’t give you any information about the outcome of event <span class="math inline">\(B\)</span>. Thus, we can use conditional statements to also show that two events are independent if <span class="math inline">\(P(A|B) = P(A)\)</span>.</p>
<p>In simple random sampling, we assume that any two samples are independent. In cluster sampling, we assume that samples within a cluster are not independent, but clusters are independent of each other.</p>
<p><strong>Fact:</strong> <em>If <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are independent events, then <span class="math inline">\(P(A|B) = P(A)\)</span> and <span class="math inline">\(P(B|A) = P(B)\)</span>.</em></p>
<p>These statements follow directly from the given definitions.</p>
<p><strong>Example:</strong> Suppose that we are interested in the relationship between the color and the type of car. Specifically I will divide the car world into convertibles and non-convertibles and the colors into red and non-red.</p>
<p>Suppose that convertibles make up just 10% of the domestic automobile market. This is to say <span class="math inline">\(P(\;Convertable\;)=0.10\)</span>. Of the non-convertibles, red is not unheard of but it isn’t common either. So suppose <span class="math inline">\(P(\;Red\;|\;NonConvertable\;)=0.15\)</span>. However red is an extremely popular color for convertibles so let <span class="math inline">\(P(\;Red\;|\;Convertable\;)=0.60\)</span>.</p>
<p>Given the above information, we can create the following table:</p>
<table>
<thead>
<tr class="header">
<th align="right"><span class="math inline">\(\,\)</span></th>
<th align="center">Convertible</th>
<th align="center">Not Convertible</th>
<th align="center"><span class="math inline">\(\,\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><strong>Red</strong></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="right"><strong>Not Red</strong></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="right"><span class="math inline">\(\,\)</span></td>
<td align="center"><strong>10%</strong></td>
<td align="center"><strong>90%</strong></td>
<td align="center"><strong>100%</strong></td>
</tr>
</tbody>
</table>
<p>We can fill in some of the table using our the definition of conditional probability. For example:
<span class="math display">\[\begin{aligned}
P\left(Red\,\cap\,Convertable\right)    &amp;= P\left(Red\,|\,Convertable\right)\,P\left(Convertable\right) \\
    &amp;=  0.60*0.10 \\
    &amp;=  0.06
  \end{aligned}\]</span></p>
<p>Lets think about what this conditional probability means. Of the <span class="math inline">\(90\%\)</span> of cars that are not convertibles, <span class="math inline">\(15\%\)</span> those non-convertibles are red and therefore the proportion of cars that are red non-convertibles is <span class="math inline">\(0.90*0.15=0.135\)</span>. Of the <span class="math inline">\(10\%\)</span> of cars that are convertibles, <span class="math inline">\(60\%\)</span> of those are red and therefore proportion of cars that are red convertibles is <span class="math inline">\(0.10*0.60=0.06\)</span>. Thus the total percentage of red cars is actually
<span class="math display">\[\begin{aligned}P\left(\,Red\,\right)  
  &amp;= P\left(\;Red\;\cap\;Convertible\;\right)+P\left(\,Red\,\cap\,NonConvertible\,\right)\\
    &amp;= P\left(\,Red\,|\,Convertable\,\right)P\left(\,Convertible\,\right)+P\left(\,Red\,|\,NonConvertible\,\right)P\left(\,NonConvertible\,\right)\\
    &amp;=  0.60*0.10+0.15*0.90\\
    &amp;=  0.06+0.135\\
    &amp;=  0.195
    \end{aligned}\]</span>
So when I ask for <span class="math inline">\(P(\;red\;|\;convertable\;)\)</span>, I am narrowing my space of cars to consider only convertibles. While there percentage of cars that are red and convertible is just 6% of all cars, when I restrict myself to convertibles, we see that the percentage of this smaller set of cars that are red is 60%.</p>
<p>Notice that because <span class="math inline">\(P\left(Red\right)=0.195\ne0.60=P\left(Red\,|\,Convertable\right)\)</span> then the events <span class="math inline">\(Red\)</span> and <span class="math inline">\(Convertable\)</span> are not independent.</p>
</div>
<div id="summary-of-probability-rules" class="section level3" number="2.2.3">
<h3><span class="header-section-number">2.2.3</span> Summary of Probability Rules</h3>
<p>Here we give a short summary of the most frequently used rules.</p>
<p><span class="math display">\[0 \le P\left(A\right) \le 1\]</span></p>
<p><span class="math display">\[P\left(A\right)+P\left(A^c\right)=1\]</span>
<span class="math display">\[P\left(A\cup B\right) =   P\left(A\right)+P\left(B\right)-P\left(A\cap B\right)\]</span>
<span class="math display">\[P\left(A\cap B\right) =   \begin{cases}
P\left(A\,|\,B\right)P\left(B\right)\\
P\left(B\,|\,A\right)P\left(A\right)\\
P(A)P(B)\;\; &amp; \textrm{ if A,B are independent}
\end{cases}\]</span></p>
<p><span class="math display">\[P\left(A\,|\,B\right) =   \frac{P\left(A\cap B\right)}{P\left(B\right)}\]</span></p>
</div>
</div>
<div id="discrete-random-variables" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Discrete Random Variables</h2>
<p>The different types of probability distributions (and therefore your analysis
method) can be divided into two general classes:</p>
<ol style="list-style-type: decimal">
<li><p>Continuous Random Variables - the variable takes on numerical values and could,
in principle, take any of an uncountable number of values. In practical terms,
if fractions or decimal points in the number make sense, it is usually continuous.</p></li>
<li><p>Discrete Random Variables - the variable takes on one of small set of values
(or only a countable number of outcomes). In practical terms, if fractions
or decimals points don’t make sense, it is usually discrete.
Previously we distinguished between categorical (e.g. Ford, Chevy, Tesla)
and numerical discrete (e.g. number of offspring) but because we could
arbitrarily map the categorical labels to the integers, probability theory
generally glosses over that distinction and only worries about if their
is ordering to the categorical levels.</p></li>
</ol>
<p>Examples:</p>
<ol style="list-style-type: decimal">
<li>Presence or Absence of wolves in a State?</li>
<li>Number of Speeding Tickets received?</li>
<li>Tree girth (in cm)?</li>
<li>Photosynthesis rate?</li>
</ol>
<div id="introduction-to-discrete-random-variables" class="section level3" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> Introduction to Discrete Random Variables</h3>
<p>The following facts hold for discrete random variables:</p>
<ol style="list-style-type: decimal">
<li>The probability associated with every value lies between 0 and 1</li>
<li>The sum of all probabilities for all values is equal to 1</li>
<li>Probabilities for discrete RVs are additive. i.e., <span class="math inline">\(P(3\textrm{ or }4)=P(3)+P(4)\)</span></li>
</ol>
<div id="expected-value" class="section level4" number="2.3.1.1">
<h4><span class="header-section-number">2.3.1.1</span> Expected Value</h4>
<p>Example: Consider the discrete random variable <span class="math inline">\(S\)</span>, the sum of two fair dice.</p>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<p>We often want to ask ‘What is expected value of this distribution?’ You might
think about taking a really, really large number of samples from this distribution
and then taking the mean of that really really big sample. We define the expected
value (often denoted by <span class="math inline">\(\mu\)</span>) as a weighted average of the possible values and
the weights are the proportions with which those values occur.</p>
<p><span class="math display">\[\mu=E[S]  =   \sum_{\textrm{possible }s}\;s\cdot P\left(S=s\right)\]</span>
In this case, we have that
<span class="math display">\[\begin{aligned} \mu = E[S] 
&amp;=  \sum_{s=2}^{12}s\cdot P(S=s) \\
&amp;=  2\cdot P\left(S=2\right)+3\cdot P\left(S=3\right)+\dots+11\cdot P\left(S=11\right)+12\cdot P\left(S=12\right) \\
&amp;=  2\left(\frac{1}{36}\right)+3\left(\frac{2}{36}\right)+\dots+11\left(\frac{2}{36}\right)+12\left(\frac{1}{36}\right) \\
&amp;=  7
\end{aligned}\]</span></p>
</div>
<div id="variance" class="section level4" number="2.3.1.2">
<h4><span class="header-section-number">2.3.1.2</span> Variance</h4>
<p>Similarly we could define the variance of <span class="math inline">\(S\)</span> (which we often denote <span class="math inline">\(\sigma^{2}\)</span>)
as a weighted average of the squared-deviations that could occur.
<span class="math display">\[ \sigma^{2}=V[S]  = \sum_{\textrm{possible }s}\; (s-\mu)^2 \cdot P\left(S=s\right)\]</span>
which in this example can be calculated as
<span class="math display">\[\begin{aligned} \sigma^{2}=V[S] 
  &amp;= \sum_{s=2}^{12}\left(s-\mu\right)^{2}P(S=s) \\
    &amp;= (2-7)^{2}\left(\frac{1}{36}\right)+(3-7)^{2}\left(\frac{2}{36}\right)+\dots+(12-7)^{2}\left(\frac{1}{36}\right) \\
    &amp;= \frac{35}{6}=5.8\bar{3}
    \end{aligned}\]</span></p>
<p>We could interpret the expectation as the sample mean of an infinitely large
sample, and the variance as the sample variance of the same infinitely large
sample. These are two very important numbers that describe the distribution.</p>
<p><strong>Example:</strong> Aubrey is a massage therapist and over the last year, the number
of clients she sees per work day (denoted Y) varied according the following table:</p>
<table>
<thead>
<tr class="header">
<th align="right">Number of Clients</th>
<th align="center">0</th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">3</th>
<th align="center">4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><strong>Frequency/Probability</strong></td>
<td align="center">0.30</td>
<td align="center">0.35</td>
<td align="center">0.20</td>
<td align="center">0.10</td>
<td align="center">0.05</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="prob.html#cb24-1" aria-hidden="true" tabindex="-1"></a>distr <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(    <span class="at">clients =</span> <span class="fu">c</span>( <span class="dv">0</span>,   <span class="dv">1</span>,    <span class="dv">2</span>,    <span class="dv">3</span>,    <span class="dv">4</span>   ),    <span class="co"># two columns </span></span>
<span id="cb24-2"><a href="prob.html#cb24-2" aria-hidden="true" tabindex="-1"></a>                    <span class="at">probability =</span> <span class="fu">c</span>(<span class="fl">0.3</span>, <span class="fl">0.35</span>, <span class="fl">0.20</span>, <span class="fl">0.10</span>, <span class="fl">0.05</span> ) )   <span class="co"># </span></span>
<span id="cb24-3"><a href="prob.html#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(distr, <span class="fu">aes</span>(<span class="at">x=</span>clients)) <span class="sc">+</span>                   <span class="co"># graph with clients as the x-axis</span></span>
<span id="cb24-4"><a href="prob.html#cb24-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y=</span>probability)) <span class="sc">+</span>                <span class="co"># where the dots go</span></span>
<span id="cb24-5"><a href="prob.html#cb24-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_linerange</span>(<span class="fu">aes</span>(<span class="at">ymax=</span>probability, <span class="at">ymin=</span><span class="dv">0</span>)) <span class="sc">+</span> <span class="co"># the vertical lines       </span></span>
<span id="cb24-6"><a href="prob.html#cb24-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()                                      <span class="co"># set background color...</span></span></code></pre></div>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<p>Because this is the long term relative frequency of the number of clients (over
200 working days!), it is appropriate to interpret these frequencies as probabilities.
This table and graph is often called a <strong>probability mass function (pmf)</strong> because
it lists how the probability is spread across the possible values of the random
variable. We might next ask ourselves what is the average number of clients per day?</p>
<p><span class="math display">\[\begin{aligned} E\left(Y\right)   
  &amp;=    \sum_{\textrm{possible }y}y\,P\left(Y=y\right) \\
    &amp;=  \sum_{y=0}^{4}y\,P\left(Y=y\right) \\
    &amp;=  0\,P\left(Y=0\right)+1\,P\left(Y=1\right)+2\,P\left(Y=2\right)+3\,P\left(Y=3\right)+4\,P\left(Y=4\right) \\
    &amp;=  0\left(0.3\right)+1\left(0.35\right)+2\left(0.20\right)+3\left(0.10\right)+4\left(0.05\right) \\
    &amp;=  1.25 \end{aligned}\]</span></p>
<p>Notice that this number is not an integer and therefore is not a value that
<span class="math inline">\(Y\)</span> could actually take on. You might be tempted to therefore round it to the
nearest integer. That would be wrong. The rational is that if we wanted to
estimate the number of clients she has per month (and thus her income), we would
have a worse estimate if we used the rounded number.</p>
<p>Another example of a case where rounding would be inappropriate is in gambling
situations where the amount won or lost per hand isn’t particularly important but
the average amount won or lost over hundreds or thousands of plays is what matters.
A Roulette wheel has 18 red and 18 black slots along with 2 green. If you bet $1
on red, you could either win a dollar or lose a dollar. However, because the
probabilities are</p>
<table>
<thead>
<tr class="header">
<th align="right"></th>
<th align="center">Win ( + $1 )</th>
<th align="center">Lose (- $1)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"><strong>Probability</strong></td>
<td align="center"><span class="math inline">\(\frac{18}{38}\)</span></td>
<td align="center"><span class="math inline">\(\frac{20}{38}\)</span></td>
</tr>
</tbody>
</table>
<p>then the persons expected winnings per play are:</p>
<p><span class="math display">\[ \begin{aligned}E[W] 
  = \sum_{\textrm{possible }w}w\,P\left(W=w\right) 
  =  1 \left(\frac{18}{38} \right) + -1 \left( \frac{20}{38} \right) 
  =  -0.0526 \end{aligned}\]</span></p>
<p>So for every Black/Red bet, the player should expect to lose 5.2 cents. While
this number is small, it is enough to make the casino millions of dollars over
the long run.</p>
<p>Returning to the massage therapy example, assuming that successive days are
independent (which might be a bad assumption) what is the probability she has
two days in a row with no clients?
<span class="math display">\[\begin{aligned}P\left(\textrm{0 on day1 }and\textrm{ 0 on day2}\right)    
  &amp;=    P\left(\textrm{0 on day 1}\right)P\left(\textrm{0 on day 2}\right) \\
    &amp;=  \left(0.3\right)\left(0.3\right) \\
    &amp;=  0.09 \end{aligned}\]</span></p>
<p>What is the variance of this distribution?
<span class="math display">\[\begin{aligned}V\left(Y\right)    
  &amp;= \sum_{\textrm{possible y}}\,\left(y-\mu\right)^{2}\,P\left(Y=y\right) \\
    &amp;= \sum_{y=0}^{4}\,\left(y-\mu\right)^{2}P\left(Y=y\right) \\
    &amp;=  \left(0-1.25\right)^{2}\left(0.3\right)+\left(1-1.25\right)^{2}\left(0.35\right)+\left(2-1.25\right)^{2}\left(0.20\right)+\left(3-1.25\right)^{2}\left(0.10\right)+\left(4-1.25\right)^{2}\left(0.05\right) \\
    &amp;=  1.2875 \end{aligned}\]</span></p>
<p>Note on Notation: There is a difference between the upper and lower case letters
we have been using to denote a random variable. In general, we let the upper case
denote the random variable and the lower case as a value that the the variable
could possibly take on. So in the massage example, the number of clients seen
per day <span class="math inline">\(Y\)</span> could take on values <span class="math inline">\(y=0,1,2,3,\)</span> or <span class="math inline">\(4\)</span>.</p>
</div>
</div>
</div>
<div id="common-discrete-distributions" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> Common Discrete Distributions</h2>
<div id="binomial-distribution" class="section level3" number="2.4.1">
<h3><span class="header-section-number">2.4.1</span> Binomial Distribution</h3>
<p><strong>Example:</strong> Suppose we are trapping small mammals in the desert and we spread
out three traps. Assume that the traps are far enough apart that having one being
filled doesn’t affect the probability of the others being filled and that all
three traps have the same probability of being filled in an evening. Denote the
event that a trap is filled with a critter as <span class="math inline">\(C_{i}\)</span> and denote the event that
the trap is empty as <span class="math inline">\(E_{i}\)</span>. Denote the probability that a trap is filled by
<span class="math inline">\(\pi=0.8\)</span>. (This sort of random variable is often referred to as a Bernoulli RV.)</p>
<p>The possible outcomes are</p>
<table>
<thead>
<tr class="header">
<th align="center">Outcome</th>
<th align="center"><span class="math inline">\(\,\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(E_1, E_2, E_3\)</span></td>
<td align="center"><span class="math inline">\(\,\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(C_1, E_2, E_3\)</span></td>
<td align="center"><span class="math inline">\(\,\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(E_1, C_2, E_3\)</span></td>
<td align="center"><span class="math inline">\(\,\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(E_1, E_2, C_3\)</span></td>
<td align="center"><span class="math inline">\(\,\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(C_1, C_2, E_3\)</span></td>
<td align="center"><span class="math inline">\(\,\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(C_1, E_2, C_3\)</span></td>
<td align="center"><span class="math inline">\(\,\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(E_1, C_2, C_3\)</span></td>
<td align="center"><span class="math inline">\(\,\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(C_1, C_2, C_3\)</span></td>
<td align="center"><span class="math inline">\(\,\)</span></td>
</tr>
</tbody>
</table>
<p>Because these are far apart enough in space that the outcome of Trap1 is independent
of Trap2 and Trap3, then
<span class="math display">\[P(E_{1}\cap C_{2}\cap E_{3})  =   P(E_{1})P(C_{2})P(E_{3})
    =   (1-0.8)0.8(1-0.8)
    =   0.032\]</span>
<strong>Notice how important the assumption of independence is!!!</strong> Similarly we could
calculate the probabilities for the rest of the table.</p>
<table>
<thead>
<tr class="header">
<th align="center">Outcome</th>
<th align="center">Probability</th>
<th align="center"><span class="math inline">\(S\)</span> Outcome</th>
<th align="center">Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(E_1, E_2, E_3\)</span></td>
<td align="center">0.008</td>
<td align="center"><span class="math inline">\(S=0\)</span></td>
<td align="center">0.008</td>
</tr>
<tr class="even">
<td align="center">——————-</td>
<td align="center">—————</td>
<td align="center">————-</td>
<td align="center">—————</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(C_1, E_2, E_3\)</span></td>
<td align="center">0.032</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(E_1, C_2, E_3\)</span></td>
<td align="center">0.032</td>
<td align="center"><span class="math inline">\(S=1\)</span></td>
<td align="center"><span class="math inline">\(3(0.032) = 0.096\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(E_1, E_2, C_3\)</span></td>
<td align="center">0.032</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center">——————-</td>
<td align="center">—————</td>
<td align="center">————-</td>
<td align="center">—————</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(C_1, C_2, E_3\)</span></td>
<td align="center">0.128</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(C_1, E_2, C_3\)</span></td>
<td align="center">0.128</td>
<td align="center"><span class="math inline">\(S=2\)</span></td>
<td align="center"><span class="math inline">\(3(0.128) = 0.384\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(E_1, C_2, C_3\)</span></td>
<td align="center">0.128</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center">——————-</td>
<td align="center">—————</td>
<td align="center">————-</td>
<td align="center">—————</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(C_1, C_2, C_3\)</span></td>
<td align="center">0.512</td>
<td align="center"><span class="math inline">\(S=3\)</span></td>
<td align="center"><span class="math inline">\(0.512\)</span></td>
</tr>
</tbody>
</table>
<p>Next we are interested in the random variable <span class="math inline">\(S\)</span>, the number of traps that were filled:</p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(S\)</span> Outcome</th>
<th align="center">Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(S=0\)</span></td>
<td align="center"><span class="math inline">\(0.008\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(S=1\)</span></td>
<td align="center"><span class="math inline">\(0.096\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(S=2\)</span></td>
<td align="center"><span class="math inline">\(0.384\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(S=3\)</span></td>
<td align="center"><span class="math inline">\(0.512\)</span></td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(S\)</span> is an example of a Binomial Random Variable. A binomial experiment is one that:</p>
<ol style="list-style-type: decimal">
<li>Experiment consists of <span class="math inline">\(n\)</span> identical trials.</li>
<li>Each trial results in one of two outcomes (Heads/Tails, presence/absence). One
will be labeled a success and the other a failure.</li>
<li>The probability of success on a single trial is equal to <span class="math inline">\(\pi\)</span> and remains the
same from trial to trial.</li>
<li>The trials are independent (this is implied from property 3).</li>
<li>The random variable <span class="math inline">\(Y\)</span> is the number of successes observed during <span class="math inline">\(n\)</span> trials.</li>
</ol>
<p>Recall that the probability mass function (pmf) describes how the probability is
spread across the possible outcomes, and in this case, I can describe this via a
nice formula. The pmf of a a binomial random variable <span class="math inline">\(X\)</span> taken from <span class="math inline">\(n\)</span> trials
each with probability of success <span class="math inline">\(\pi\)</span> is</p>
<p><span class="math display">\[P(X=x)=\underbrace{\frac{n!}{x!(n-x)!}}_{orderings}\;\underbrace{\pi^{x}}_{y\,successes}\;\underbrace{(1-\pi)^{n-x}}_{n-y\,failures}\]</span></p>
<p>where we define <span class="math inline">\(n!=n(n-1)\dots(2)(1)\)</span> and further define <span class="math inline">\(0!=1\)</span>. Often the
ordering term is written more compactly as
<span class="math display">\[{n \choose x}=\frac{n!}{x!\left(n-x\right)!}\]</span>.</p>
<p>For our small mammal example we can create a graph that shows the binomial
distribution with the following R code:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="prob.html#cb25-1" aria-hidden="true" tabindex="-1"></a>dist <span class="ot">&lt;-</span> <span class="fu">data.frame</span>( <span class="at">x=</span><span class="dv">0</span><span class="sc">:</span><span class="dv">3</span> ) <span class="sc">%&gt;%</span> </span>
<span id="cb25-2"><a href="prob.html#cb25-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">probability =</span> <span class="fu">dbinom</span>(x, <span class="at">size=</span><span class="dv">3</span>, <span class="at">prob=</span><span class="fl">0.8</span>))</span>
<span id="cb25-3"><a href="prob.html#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dist, <span class="fu">aes</span>(<span class="at">x=</span>x)) <span class="sc">+</span></span>
<span id="cb25-4"><a href="prob.html#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y=</span>probability)) <span class="sc">+</span></span>
<span id="cb25-5"><a href="prob.html#cb25-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_linerange</span>(<span class="fu">aes</span>(<span class="at">ymax=</span>probability, <span class="at">ymin=</span><span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb25-6"><a href="prob.html#cb25-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&#39;Binomial distribution: n=3, p=0.8&#39;</span>) <span class="sc">+</span></span>
<span id="cb25-7"><a href="prob.html#cb25-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
<p>To calculate the height of any of these bars, we can evaluate the pmf at the
desired point. For example, to calculate the probability the number of full
traps is 2, we calculate the following</p>
<p><span class="math display">\[\begin{aligned} P(X=2)    
  &amp;=    {3 \choose 2}\left(0.8\right)^{2}\left(1-0.8\right)^{3-2} \\
    &amp;=  \frac{3!}{2!(3-2)!}(0.8)^{2}(0.2)^{3-2} \\
    &amp;=  \frac{3\cdot2\cdot1}{(2\cdot1)1}\;(0.8)^{2}(0.2) \\
    &amp;=  3(0.128) \\
    &amp;=  0.384 \end{aligned}\]</span></p>
<p>You can use R to calculate these probabilities. In general, for any distribution,
the “d-function” gives the distribution function (pmf or pdf). So to get R to do
the preceding calculation we use:</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="prob.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># If    X ~ Binomial(n=3, pi=0.8)</span></span>
<span id="cb26-2"><a href="prob.html#cb26-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Then  P( X = 2 | n=3, pi=0.8 ) =</span></span>
<span id="cb26-3"><a href="prob.html#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="dv">2</span>, <span class="at">size=</span><span class="dv">3</span>, <span class="at">prob=</span><span class="fl">0.8</span>)</span></code></pre></div>
<pre><code>## [1] 0.384</code></pre>
<p>The expectation of this distribution can be shown to be
<span class="math display">\[\begin{aligned}E[X]   
  &amp;=    \sum_{x=0}^{n}x\,P(X=x) \\
    &amp;=  \sum_{x=0}^{n}x\;\frac{n!}{x!\left(n-x\right)!}\pi^{x}\left(1-\pi\right)^{n-x}\\
    &amp;=  \vdots \\
    &amp;=  n\pi \end{aligned}\]</span></p>
<p>and the variance can be similarly calculated
<span class="math display">\[\begin{aligned} V[X]  
  &amp;=    \sum_{x=0}^{n}\left(x-E\left[X\right]\right)^{2}\,P\left(X=x|n,\pi\right) \\
    &amp;=  \sum_{x=0}^{n}\left(x-E\left[X\right]\right)^{2}\;\frac{n!}{x!\left(n-x\right)!}\pi^{x}\left(1-\pi\right)^{n-x} \\
    &amp;=  \vdots \\
    &amp;=  n\pi(1-\pi) \end{aligned}\]</span></p>
<p><strong>Example:</strong> Suppose a bird survey only captures the presence or absence of a
particular bird (say the mountain chickadee). Assuming the true presence proportion
at national forest sites around Flagstaff is <span class="math inline">\(\pi=0.1\)</span>, then for <span class="math inline">\(n=20\)</span> randomly
chosen sites, the number of sites in which the bird was observed would have the
following PMF.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="prob.html#cb28-1" aria-hidden="true" tabindex="-1"></a>dist <span class="ot">&lt;-</span> <span class="fu">data.frame</span>( <span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">20</span> ) <span class="sc">%&gt;%</span> </span>
<span id="cb28-2"><a href="prob.html#cb28-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">probability =</span> <span class="fu">dbinom</span>(x, <span class="at">size=</span><span class="dv">20</span>, <span class="at">prob=</span><span class="fl">0.1</span>))</span>
<span id="cb28-3"><a href="prob.html#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dist, <span class="fu">aes</span>(<span class="at">x=</span>x)) <span class="sc">+</span></span>
<span id="cb28-4"><a href="prob.html#cb28-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y=</span>probability)) <span class="sc">+</span></span>
<span id="cb28-5"><a href="prob.html#cb28-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_linerange</span>(<span class="fu">aes</span>(<span class="at">ymax=</span>probability, <span class="at">ymin=</span><span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb28-6"><a href="prob.html#cb28-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&#39;Binomial distribution: n=20, p=0.1&#39;</span>) <span class="sc">+</span></span>
<span id="cb28-7"><a href="prob.html#cb28-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">&#39;Number of Sites Occupied&#39;</span>) <span class="sc">+</span></span>
<span id="cb28-8"><a href="prob.html#cb28-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-35-1.png" width="672" /></p>
<p>Often we are interested in questions such as <span class="math inline">\(P(X\le2)\)</span> which is the probability
that we see 2 or fewer of the sites being occupied by mountain chickadee. These
calculations can be tedious to calculate by hand but R will calculate these
cumulative distribution function values for you using the “p-function.” This
cumulative distribution function gives the sum of all values up to and including
the number given.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="prob.html#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P(X=0) + P(X=1) + P(X=2)</span></span>
<span id="cb29-2"><a href="prob.html#cb29-2" aria-hidden="true" tabindex="-1"></a>sum <span class="ot">&lt;-</span> <span class="fu">dbinom</span>(<span class="dv">0</span>, <span class="at">size=</span><span class="dv">20</span>, <span class="at">prob=</span><span class="fl">0.1</span>) <span class="sc">+</span> </span>
<span id="cb29-3"><a href="prob.html#cb29-3" aria-hidden="true" tabindex="-1"></a>       <span class="fu">dbinom</span>(<span class="dv">1</span>, <span class="at">size=</span><span class="dv">20</span>, <span class="at">prob=</span><span class="fl">0.1</span>) <span class="sc">+</span> </span>
<span id="cb29-4"><a href="prob.html#cb29-4" aria-hidden="true" tabindex="-1"></a>       <span class="fu">dbinom</span>(<span class="dv">2</span>, <span class="at">size=</span><span class="dv">20</span>, <span class="at">prob=</span><span class="fl">0.1</span>)</span>
<span id="cb29-5"><a href="prob.html#cb29-5" aria-hidden="true" tabindex="-1"></a>sum</span></code></pre></div>
<pre><code>## [1] 0.6769268</code></pre>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="prob.html#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P(X &lt;= 2)</span></span>
<span id="cb31-2"><a href="prob.html#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="fu">pbinom</span>(<span class="dv">2</span>, <span class="at">size=</span><span class="dv">20</span>, <span class="at">prob=</span><span class="fl">0.1</span>)</span></code></pre></div>
<pre><code>## [1] 0.6769268</code></pre>
<p>In general we will be interested in asking four different questions about a distribution.</p>
<ol style="list-style-type: decimal">
<li>What is the height of the probability mass function (or probability density function).
For discrete variable <span class="math inline">\(Y\)</span> this is <span class="math inline">\(P\left(Y=y\right)\)</span> for whatever value of <span class="math inline">\(y\)</span>
we want. In R, this will be the <code>d</code>-function.</li>
<li>What is the probability of observing a value less than or equal to <span class="math inline">\(y\)</span>? In
other words, to calculate <span class="math inline">\(P\left(Y\le y\right)\)</span>. In R, this will be the <code>p</code>-function.</li>
<li>What is a particular quantile of a distribution? For example, what value separates
the lower <span class="math inline">\(25\%\)</span> from the upper <span class="math inline">\(75\%\)</span>? In R, this will be the <code>q</code>-function.</li>
<li>Generate a random sample of values from a specified distribution. In R, this
will be the <code>r</code>-function.</li>
</ol>
</div>
<div id="poisson-distribution" class="section level3" number="2.4.2">
<h3><span class="header-section-number">2.4.2</span> Poisson Distribution</h3>
<p>A commonly used distribution for count data is the Poisson.</p>
<ol style="list-style-type: decimal">
<li>Number of customers arriving over a 5 minute interval</li>
<li>Number of birds observed during a 10 minute listening period</li>
<li>Number of prairie dog towns per 1000 hectares</li>
<li>Number of alga clumps per cubic meter of lake water</li>
</ol>
<p>A discrete RV is a Poisson RV if the following conditions apply:</p>
<ol style="list-style-type: decimal">
<li>Two or more events do not occur at precisely the same time or in the same space</li>
<li>The occurrence of an event in a given period of time or region of space is
independent of the occurrence of the event in a non overlapping period or region.</li>
<li>The expected number of events during one period or region, <span class="math inline">\(\lambda\)</span>, is the
same in all periods or regions of the same size.</li>
</ol>
<p>Assuming that these conditions hold for some count variable <span class="math inline">\(Y\)</span>, the the
probability mass function is given by
<span class="math display">\[P(Y=y)=\frac{\lambda^{y}e^{-\lambda}}{y!}\]</span>
where <span class="math inline">\(\lambda\)</span> is the expected number of events over 1 unit of time or space
and <span class="math inline">\(e\)</span> is the constant <span class="math inline">\(2.718281828\dots\)</span>.</p>
<p><span class="math display">\[E[Y]  =   \lambda\]</span>
<span class="math display">\[Var[Y]    =   \lambda\]</span></p>
<p><strong>Example:</strong> Suppose we are interested in the population size of small mammals in
a region. Let <span class="math inline">\(Y\)</span> be the number of small mammals caught in a large trap over a 12
hour period. Finally, suppose that <span class="math inline">\(Y\sim Poisson(\lambda=2.3)\)</span>. What is the
probability of finding exactly 4 critters in our trap?
<span class="math display">\[P(Y=4)    =   \frac{2.3^{4}\,e^{-2.3}}{4!} =  0.1169\]</span>
What about the probability of finding at most 4?
<span class="math display">\[\begin{aligned} P(Y\le4) 
  &amp;=    P(Y=0)+P(Y=1)+P(Y=2)+P(Y=3)+P(Y=4) \\
    &amp;=  0.1003+0.2306+0.2652+0.2033+0.1169 \\
    &amp;=  0.9163 \end{aligned}\]</span></p>
<p>What about the probability of finding 5 or more?
<span class="math display">\[P(Y\ge5)  =   1-P(Y\le4) =    1-0.9163 =  0.0837\]</span></p>
<p>These calculations can be done using the distribution function (d-function) for
the Poisson and the cumulative distribution function (p-function).</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="prob.html#cb33-1" aria-hidden="true" tabindex="-1"></a>dist <span class="ot">&lt;-</span> <span class="fu">data.frame</span>( <span class="at">NumCaught =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">10</span> ) <span class="sc">%&gt;%</span></span>
<span id="cb33-2"><a href="prob.html#cb33-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>( <span class="at">probability =</span> <span class="fu">dpois</span>( NumCaught, <span class="at">lambda=</span><span class="fl">2.3</span> ) )</span>
<span id="cb33-3"><a href="prob.html#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dist, <span class="fu">aes</span>(<span class="at">x=</span>NumCaught)) <span class="sc">+</span></span>
<span id="cb33-4"><a href="prob.html#cb33-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>( <span class="fu">aes</span>(<span class="at">y=</span>probability) ) <span class="sc">+</span></span>
<span id="cb33-5"><a href="prob.html#cb33-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_linerange</span>(<span class="fu">aes</span>( <span class="at">ymax=</span>probability, <span class="at">ymin=</span><span class="dv">0</span>)) <span class="sc">+</span></span>
<span id="cb33-6"><a href="prob.html#cb33-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&#39;Poisson Distribution with  &#39;</span>, lambda <span class="sc">==</span> <span class="fl">2.3</span>))) <span class="sc">+</span></span>
<span id="cb33-7"><a href="prob.html#cb33-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x=</span><span class="st">&#39;Number Caught&#39;</span>) <span class="sc">+</span></span>
<span id="cb33-8"><a href="prob.html#cb33-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()            </span></code></pre></div>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="prob.html#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P( Y = 4)</span></span>
<span id="cb34-2"><a href="prob.html#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dpois</span>(<span class="dv">4</span>, <span class="at">lambda=</span><span class="fl">2.3</span>)</span></code></pre></div>
<pre><code>## [1] 0.1169022</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="prob.html#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P( Y &lt;= 4)</span></span>
<span id="cb36-2"><a href="prob.html#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ppois</span>(<span class="dv">4</span>, <span class="at">lambda=</span><span class="fl">2.3</span>)</span></code></pre></div>
<pre><code>## [1] 0.9162493</code></pre>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="prob.html#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1-P(Y &lt;= 4)  ==  P( Y &gt; 4)  ==  P( Y &gt;= 5)</span></span>
<span id="cb38-2"><a href="prob.html#cb38-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">ppois</span>(<span class="dv">4</span>, <span class="fl">2.3</span>)</span></code></pre></div>
<pre><code>## [1] 0.08375072</code></pre>
</div>
</div>
<div id="continuous-random-variables" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> Continuous Random Variables</h2>
<p>Continuous random variables can take on an (uncountably) infinite number of values,
and this results in a few obnoxious mathematical differences between how we handle
continuous and discrete random variables. In particular, the probability that a
continuous random variable <span class="math inline">\(X\)</span> will take on a particular value will be zero, so
we will be interested in finding the probability that the random variable is in
some interval instead. Wherever we had a summation, <span class="math inline">\(\sum\)</span>, we will instead have
an integral, but because many students haven’t had calculus, we will resort to
using R or tables of calculated values.</p>
<div id="uniform01-distribution" class="section level3" number="2.5.1">
<h3><span class="header-section-number">2.5.1</span> Uniform(0,1) Distribution</h3>
<p>Suppose you wish to draw a random number number between 0 and 1 and any two
intervals of equal size should have the same probability of the value being in
them. This random variable is said to have a Uniform(0,1) distribution.</p>
<p>Because there are an infinite number of rational numbers between 0 and 1, the
probability of any particular number being selected is <span class="math inline">\(1/\infty=0\)</span>. But even
though each number has 0 probability of being selected, some number must end up
being selected. Because of this conundrum, probability theory doesn’t look at
the probability of a single number, but rather focuses on a region of numbers.</p>
<p>To make this distinction, we will define the distribution using a
<strong>probability density function (pdf)</strong> instead of the probability mass function.
In the discrete case, we had to constrain the probability mass function to sum
to 1. In the continuous case, we have to constrain the probability density function
to integrate to 1.</p>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-39-1.png" width="672" /></p>
<p>Finding the area under the curve of a particular density function <span class="math inline">\(f(x)\)</span> usually
requires the use of calculus, but since this isn’t a calculus course, we will
resort to using R or tables of calculated values.</p>
</div>
<div id="exponential-distribution" class="section level3" number="2.5.2">
<h3><span class="header-section-number">2.5.2</span> Exponential Distribution</h3>
<p>The exponential distribution is the continuous analog of the Poisson distribution
and is often used to model the time between occurrence of successive events.
Perhaps we are modeling time between transmissions on a network, or the time
between feeding events or prey capture. If the random variable <span class="math inline">\(X\)</span> has an
Exponential distribution, its probability density function is
<span class="math display">\[f(x)=\begin{cases}
\lambda e^{-\lambda x} &amp; x\ge0\;\textrm{ and }\;\lambda&gt;0\\
0 &amp; \textrm{otherwise}
\end{cases}\]</span></p>
<p>Analogous to the discrete distributions, we can define the Expectation and
Variance of these distributions by replacing the summation with an integral
<span class="math display">\[\mu = E[X] =  \int_{0}^{\infty}x\,f(x)\,dx = \dots = \frac{1}{\lambda} \]</span>
<span class="math display">\[\sigma^2 = Var[X] =   \int_{0}^{\infty}\left(x-\mu\right)^{2}\,f\left(x\right)\,dx =  \dots = \frac{1}{\lambda^{2}}\]</span></p>
<p>Because the exponential distribution is defined by the rate of occurrence of an
event, increasing that rate decreases the time between events. Furthermore because
the rate of occurrence cannot be negative, we restrict <span class="math inline">\(\lambda&gt;0\)</span>.</p>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
<p><strong>Example:</strong> Suppose the time between insect captures <span class="math inline">\(X\)</span> during a summer evening
for a species of bat follows a exponential distribution with capture rate of
<span class="math inline">\(\lambda=2\)</span> insects per minute and therefore the expected waiting time between
captures is <span class="math inline">\(1/\lambda=1/2\)</span> minute. Suppose that we are interested in the probability
that it takes a bat more than 1 minute to capture its next insect.</p>
<p><span class="math display">\[P(X&gt;1)=\]</span></p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="prob.html#cb40-1" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x=</span><span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">5</span>,<span class="at">length=</span><span class="dv">1000</span>), <span class="at">lambda =</span> <span class="dv">2</span>) <span class="sc">%&gt;%</span></span>
<span id="cb40-2"><a href="prob.html#cb40-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y=</span><span class="fu">dexp</span>(x, <span class="at">rate =</span> lambda),</span>
<span id="cb40-3"><a href="prob.html#cb40-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">grp =</span> <span class="fu">ifelse</span>( x <span class="sc">&gt;</span> <span class="dv">1</span>, <span class="st">&#39;&gt; 1&#39;</span>, <span class="st">&#39;&lt;= 1&#39;</span>))</span>
<span id="cb40-4"><a href="prob.html#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>y, <span class="at">fill=</span>grp)) <span class="sc">+</span></span>
<span id="cb40-5"><a href="prob.html#cb40-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>() <span class="sc">+</span></span>
<span id="cb40-6"><a href="prob.html#cb40-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y=</span><span class="st">&#39;density&#39;</span>) <span class="sc">+</span></span>
<span id="cb40-7"><a href="prob.html#cb40-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-41-1.png" width="672" /></p>
<p>We now must resort to calculus to find this area. Or use tables of pre-calculated
values. Or use R, remembering that p-functions give the area under the curve to
the left of the given value.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="prob.html#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># P(X &gt; 1)  == 1 - P(X &lt;= 1)  </span><span class="al">###</span><span class="co"> Complement Rule</span></span>
<span id="cb41-2"><a href="prob.html#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pexp</span>(<span class="dv">1</span>, <span class="at">rate=</span><span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.1353353</code></pre>
</div>
<div id="normal-distribution" class="section level3" number="2.5.3">
<h3><span class="header-section-number">2.5.3</span> Normal Distribution</h3>
<p>Undoubtedly the most important distribution in statistics is the normal
distribution. If my RV <span class="math inline">\(X\)</span> is normally distributed with mean <span class="math inline">\(\mu\)</span> and standard
deviation <span class="math inline">\(\sigma\)</span>, its probability density function is given by
<span class="math display">\[f(x)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left[-\frac{(x-\mu)^{2}}{2\sigma^{2}}\right]\]</span>
where <span class="math inline">\(\exp[y]\)</span> is the exponential function <span class="math inline">\(e^{y}\)</span>. We could slightly rearrange
the function to</p>
<p><span class="math display">\[f(x)=\frac{1}{\sqrt{2\pi}\sigma}\exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^{2}\right]\]</span></p>
<p>and see this distribution is defined by its expectation <span class="math inline">\(E[X]=\mu\)</span> and its
variance <span class="math inline">\(Var[X]=\sigma^{2}\)</span>. Notice I could define it using the standard
deviation <span class="math inline">\(\sigma\)</span>, and different software packages will expect it to be defined
by one or the other. R defines the normal distribution using the standard deviation.</p>
<pre><code>## Warning: It is deprecated to specify `guide = FALSE` to remove a guide. Please
## use `guide = &quot;none&quot;` instead.</code></pre>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-43-1.png" width="672" /></p>
<p><strong>Example:</strong> It is known that the heights of adult males in the US is
approximately normal with a mean of 5 feet 10 inches (<span class="math inline">\(\mu=70\)</span> inches) and a
standard deviation of <span class="math inline">\(\sigma=3\)</span> inches. One of the textbook authors is a mere 5 feet 4
inches (64 inches). What proportion of the population is shorter than the author?</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="prob.html#cb44-1" aria-hidden="true" tabindex="-1"></a>distr <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x=</span><span class="fu">seq</span>(<span class="dv">57</span>, <span class="dv">82</span>, <span class="at">length=</span><span class="dv">1000</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb44-2"><a href="prob.html#cb44-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>( <span class="at">density =</span> <span class="fu">dnorm</span>(x, <span class="at">mean=</span><span class="dv">70</span>, <span class="at">sd=</span><span class="dv">3</span>),</span>
<span id="cb44-3"><a href="prob.html#cb44-3" aria-hidden="true" tabindex="-1"></a>          <span class="at">group =</span> <span class="fu">ifelse</span>(x<span class="sc">&lt;=</span><span class="dv">64</span>, <span class="st">&#39;Shorter&#39;</span>,<span class="st">&#39;Taller&#39;</span>) )</span>
<span id="cb44-4"><a href="prob.html#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(distr, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">y=</span>density, <span class="at">fill=</span>group)) <span class="sc">+</span></span>
<span id="cb44-5"><a href="prob.html#cb44-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span></span>
<span id="cb44-6"><a href="prob.html#cb44-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>() <span class="sc">+</span></span>
<span id="cb44-7"><a href="prob.html#cb44-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="bayes_bookdown_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
<p>Using R you can easily find this</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="prob.html#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="dv">64</span>, <span class="at">mean=</span><span class="dv">70</span>, <span class="at">sd=</span><span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 0.02275013</code></pre>
</div>
</div>
<div id="r-quick-reference" class="section level2" number="2.6">
<h2><span class="header-section-number">2.6</span> R Quick Reference</h2>
<p>We give a brief summary of the distributions used most in this course and the
abbreviations used in R.</p>
<table>
<colgroup>
<col width="18%" />
<col width="17%" />
<col width="19%" />
<col width="45%" />
</colgroup>
<thead>
<tr class="header">
<th>Distribution</th>
<th>Stem</th>
<th>Parameters</th>
<th>Parameter Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Binomial</td>
<td><code>binom</code></td>
<td><code>size</code>
<code>prob</code></td>
<td>Number of Trials,
Probability of Success (per Trial)</td>
</tr>
<tr class="even">
<td>Exponential</td>
<td><code>exp</code></td>
<td><code>rate</code></td>
<td>Mean of the distribution</td>
</tr>
<tr class="odd">
<td>Normal</td>
<td><code>norm</code></td>
<td><code>mean=0</code>
<code>sd=1</code></td>
<td>Center of the distribution,
Standard deviation</td>
</tr>
<tr class="even">
<td>Uniform</td>
<td><code>unif</code></td>
<td><code>min=0</code>
<code>max=1</code></td>
<td>Minimum and
Maximum of the distribution</td>
</tr>
</tbody>
</table>
<p>All the probability distributions available in R are accessed in exactly the
same way, using a d-function, p-function, q-function, and r-function.</p>
<table>
<colgroup>
<col width="25%" />
<col width="74%" />
</colgroup>
<thead>
<tr class="header">
<th>Function</th>
<th>Result</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>d</code>-function(x)</td>
<td>The height of the probability distribution/density at <span class="math inline">\(x\)</span></td>
</tr>
<tr class="even">
<td><code>p</code>-function(x)</td>
<td><span class="math inline">\(P\left(X\le x\right)\)</span></td>
</tr>
<tr class="odd">
<td><code>q</code>-function(q)</td>
<td><span class="math inline">\(x\)</span> such that <span class="math inline">\(P\left(X\le x\right) = q\)</span></td>
</tr>
<tr class="even">
<td><code>r</code>-function(n)</td>
<td><span class="math inline">\(n\)</span> random observations from the distribution</td>
</tr>
</tbody>
</table>
<p>The <code>mosaic</code> package has versions of the p and q -functions that also print a out
nice picture of the probabilities that you ask for. These functions are named by
just adding an ‘x’ at the beginning of the function. For example <code>mosaic::xpnorm(-1)</code>.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="lab1-getting-started-with-r-rstudio.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bayes.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": "twitter"
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"toolbar": {
"position": "fixed"
},
"search": true,
"info": true
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
